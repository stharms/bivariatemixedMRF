%\documentclass[10pt, a4paper, twoside]{proc}
\documentclass[12pt, a4paper, twoside]{article}
\setlength{\parindent}{15pt}
\usepackage[compact]{titlesec}
\titlespacing{\section}{0pt}{*0}{*0}
\titlespacing{\subsection}{0pt}{*0}{*0}
\titlespacing{\subsubsection}{0pt}{*0}{*0}
\parskip=0pt
\bibliographystyle{apa}
\usepackage[margin=.8in]{geometry}
\usepackage{setspace}
\renewcommand{\baselinestretch}{2}
\usepackage{caption}
%\usepackage{subfig}
\usepackage{subcaption}
\usepackage{indentfirst}
\usepackage{enumitem}
\usepackage{ulem}
\usepackage{amsmath}
\usepackage{float}
 \usepackage{amsthm}
\usepackage{graphicx}
\usepackage{rotating}
\usepackage{undertilde}
\usepackage{tikz}
\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;} 
\usepackage{bbm}
%\usepackage{breqn}
\usepackage{hyperref}
\hypersetup{
	colorlinks,
	linktocpage,
	linktoc=all,
	citecolor=black,
	filecolor=black,
	linkcolor=black,
	urlcolor=black
}



\author{Steve Harms}
\title{A Centered Bivariate Markov Random Field Model for Mixed Response Distributions}
\date{\today} 
\begin{document}
\maketitle

\begin{abstract}
The class of Markov random field models known as auto-models provides a flexible and highly-interpretable model structure for analysis of lattice data, which may be of particular interest for research in agriculture, forestry, image construction, or genetics. This paper proposes a Markov random field model with a bivariate Binary-Gaussian response, which provides a foundation for reliable statistical inference with multivariate response distributions of mixed types in the presence of spatial dependence. Pseudo-likelihood-based estimation and inference are investigated via simulation study. the model adequately captures both covariate and spatial dependence relationships under a not-too-strong spatial dependence regime, however the definition of "strong spatial dependence" is a difficult question when distributions are mixed. The model is implemented in 2 cases: data from wheat field trials and data on observations of prairie chickens. The full bivariate model outperforms univariate and non-spatial models in capturing spatial dependence and covariate relationships together.
\end{abstract}
\newpage
\tableofcontents
\newpage
 \listoffigures
\listoftables
\newpage

\section{Introduction}\label{intro}
\subsection{Motivation}\label{motivation}
Data collected on a spatial domain have become increasingly ubiquitous in the last half-century, largely due to the expanded ability of satellite imagery and other geographic mapping systems as well as increased computing power. Many applications of spatial data involve variables collected on a discrete-indexed grid structure, especially field experiments and observational studies in domains such as agriculture and environmental science. In some applications (e.g., weather forecasting), prediction may be of interest. Many research questions, however, require inferential statements about model parameters such as regression coefficients and spatial correlation to answer a scientific question of interest. When answers to pertinent scientific questions require inference on model parameters, a clearly specified model supporting interpretable parameters is important to the analysis.
%\medskip

To motivate our model, consider data collected $n$ locations arranged on a (not necessarily regular) lattice, denoted as $\lbrace s_i: i=1,...,n \rbrace$. We have two variables of interest at each location. One variable, $Y(s_i)$, is distributed as a binary variable. The other response variable, $Z(s_i)$, is Gaussian. Let each response variable at each location be assigned to a node (vertex), such that entire structure defines a graph $G = (V,E)$ with $|V|=2n$ total nodes connected by an appropriate set of edges $E$. In Section \ref{AgTrials}, we model a binary variable that takes the value 1 if wheat at a site is slow to head and 0 otherwise as $Y(s_i)$, and model the wheat yield at a site in bushels as our continuous variable $Z(s_i)$. In Section \ref{ChickenAnalysis}, we model the presence of Greater Prairie Chickens (1 if present, 0 if not) at a location as our binary variable $Y(s_i)$, and model the vegetative cover at each locations as a continuous variable, $Z(s_i)$. We propose a flexible model for the bivariate response scenarios described above. Our framework allows us to analyze marginal mean and covariate relationships for both response variables separately, while also modeling the additional variation in the data that is due to spatial dependence and correlation between the two response variables.

Our approach is not the first model for multivariate spatially-correlated data. In Caragea and Berg (2014), a bivariate auto-logistic model is proposed for presence-absence data for two tree species collected on a grid. The model allows for spatial correlation for each tree species and also models cross-dependence between the two different species. The model proposed in this work extends the bivariate auto-logistic model where the response variables are both Bernoulli distributed. In our work, the distribution of the two response variables need not be of the same type. Specifically, we define a model for pairs of discrete and continuous random variables observed on a spatial lattice. This extension is intended to both (i) provide a model with interpretable parameters that can answer a scientific question of interest; and (ii) provide a foundation for higher-dimensional (p$>$2) Markov random field models with response variables coming from more than one family of distributions.
%\medskip

Prior research on multivariate Markov random field models primarily considers all Gaussian response variables, such as Mardia (1988) and Rue and Held (2005). Recent work in the network analysis literature focuses on constructing probabilistic models for structure detection, such as Lee and Hastie (2015) and Chen, et al. (2014). The model proposed in this work combines these two related fields. Another work that considers mixed spatially-correlated random variables is Hardouin and Cressie (2018), in which an underlying Gaussian fine-grid process is used to capture background variability on an observed coarse-scaled binary quantity (in their case, the presence/absence of corn borers). The model proposed here is similar in many ways, except the Gaussian and binary quantities are on the same discrete-indexed scale.

\subsection{Model Framework}\label{framework}
This work only considers a four-nearest neighbor edge structure, with a given interior node being connected to its four nearest neighbors of the \textit{same type} and the node at the same location of the other type. Thus any interior node has five edges connected to other nodes, with nodes on the edge/corner of the lattice having fewer than five. For visualization purposes, it may be easier to view the structure as two separate lattices that are stacked on top of each other on the grid, and then linked via a cross-dependence parameter. This structure is similar to the multivariate lattice structure in the context of a hierarchical spatial GLMM illustrated in Sain, et al.(2011). Here, the number of stacked lattices is 2 and the variables are denoted as $Y(s_i)$ and $Z(s_i)$ to distinguish the differing variable distribution types. The neighborhood and distribution structure is defined as above for simplicity and brevity, although our proposed framework can be flexibly extended to larger or more irregular structures.

For notational purposes throughout the rest of this work, we define $\boldsymbol{z}(\bar{s}_i):\lbrace z(s_j):i\neq j\rbrace$ and $\boldsymbol{y}(\bar{s}_i):\lbrace y(s_j):i\neq j\rbrace$ to be all of the nodes of the same type at all locations except $s_i$. Likewise, we define $\boldsymbol{\utilde{y}} : \lbrace y(s_i):i = 1,...,n\rbrace $ and $\boldsymbol{\utilde{z}} : \lbrace z(s_i):i = 1,...,n\rbrace$ respectively to be the collections of all random variables of the same type, including location $s_i$. The neighborhood for a location $s_i$ is denoted as $N_i$, such that $j \in N_i$ implies that location $s_j$ is a neighbor of location $s_i$. For the four-nearest neighbor structure, an interior location $s_i$ has $|N_i|=4$.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{images/Graphstructure.png}
\end{figure}

We propose a model for the bivariate graph structure wherein the binary nodes have conditional distributions that are logistic regressions and the Gaussian nodes have conditional distributions that are linear regressions. We account for spatial dependence as well as dependence between observations at the same location by adding autoregressive parameters into these conditional distributions. Let M be the number of neighbors of the \textit{same type} for an observation at location $s_i$. For a binary node at location $s_i$, we specify the distribution conditional on neighboring observations as
\begin{equation} \label{condY}
p(y(s_{i})|\boldsymbol{y}(\bar{s}_i) , z(s_{i})) = \frac{\exp\left\lbrace y(s_i)\phi(s_i)  \right\rbrace}
{1 + \exp\lbrace y(s_i)\phi(s_i)\rbrace } 	
\end{equation}
where
\begin{equation} \label{condYmean}
\phi(s_i) = \delta + \frac{\eta_{y}}{M} \sum_{j \in N_{i}} \left[y(s_j) - \frac{\exp(\delta)}{1+\exp(\delta)}\right] +\frac{\rho}{\sigma^2}(z(s_i) - \mu)     .
\end{equation}
For a Gaussian node at location $s_i$, we specify the conditional distribution as 
\begin{equation}\label{condZ}
p(z(s_{i}) | \boldsymbol{z}(\bar{s}_i) , y(s_{i})) = \frac{1}{\sqrt {2 \pi \sigma^2}} \exp\left\lbrace \frac{-1}{2\sigma^2} \left[z(s_i) - \alpha(s_i)  \right]^{2} \right\rbrace 
\end{equation}
where
\begin{equation}\label{condZmean}
\alpha(s_i) =  \mu + \frac{\eta_z}{M} \sum_{j \in N_{i}} \left(z(s_j) - \mu\right)+ \rho\left(y(s_i) - \frac{\exp{(\delta)}}{1+\exp{(\delta)}}\right)
\end{equation}
In (\ref{condYmean}) and (\ref{condZmean}), $\delta$ and $\mu$ are the respective "global" mean parameters, and we incorporate available covariate information by setting $\delta$ and/or $\mu$ equal to a linear function of the covariates, as in a typical regression setting. Parameters $\eta_y$ and $\eta_z$ are the respective spatial dependence parameters among variables of the same type. We link the two nodes at each location via $\rho$, which plays the role of a "cross-dependence" parameter.

From our conditional specification of the node distributions, we propose a corresponding joint distribution for the four-nearest neighbor structure with the form
\begin{multline} \label{fulljointprop}
p(\boldsymbol{\utilde{y},\utilde{z}}) \propto \exp\lbrace \sum_{i = 1}^{n} \left[\frac{\mu_i}{\sigma^2}z(s_i) - \frac{1}{2\sigma^2}z(s_i)^2 + \delta_i y(s_i)\right] +  \frac{\rho}{\sigma^2} \sum_{i = 1}^{n} \left[\left(z(s_i)-\mu_i\right)\left(y(s_i) - \frac{\exp{(\delta_i)}}{1+\exp{(\delta_i)}}\right)\right]\\
-\frac{1}{\sigma^2}\sum_{i=1}^{n}\sum_{j\in N_i}\left[ \frac{\eta_z}{M}\left( z(s_i)-\mu_i\right)\left(z(s_j)-\mu_j \right)\right]\\
+ \sum_{i=1}^{n}\sum_{j\in N_i}\left[\frac{\eta_y}{M}\left(y(s_i) - \frac{\exp{(\delta_i)}}{1+\exp{(\delta_i)}}\right) \left(y(s_j) - \frac{\exp{(\delta_j)}}{1+\exp{(\delta_j)}}\right)\right] \rbrace .
\end{multline}
In the joint distribution, we observe that the full model requires estimation of at least 6 parameters, $\boldsymbol{\Theta}=\lbrace\rho,\eta_y,\eta_z,\mu,\delta,\sigma^2\rbrace$, with the size of the parameter block increasing with the addition of covariates or more nuanced dependence relationships (such as anisotropy or irregular neighborhoods). The number of parameters complicates proper justification, estimation, and interpretation for the bivariate mixed MRF model when compared to the typical regression setting. We discuss some technical properties of the node-conditional distributions and corresponding joint distribution from (\ref{condY})-(\ref{fulljointprop}) in Section \ref{BivMMRF}. Before doing so, in Section \ref{prelims} we briefly review some relevant foundational literature in Markov random fields and mixed graphical models that are integral to construction of the novel model proposed in this work.

The rest of this work illustrates various properties of the centered bivariate mixed Markov random field model, and is organized as follows. Section \ref{EstimInf} outlines the procedure for estimation and inference for model parameters, and Section \ref{SimStudy} investigates the reliability of the procedure under different spatial dependence conditions. Sections \ref{AgTrials} and \ref{ChickenAnalysis} illustrate model implementation with brief examples using re-purposed agricultural field trial data and observations of Greater Prairie Chickens, respectively. The final section concludes with a summary and discussion of possible avenues for future work.

\section{Preliminaries}\label{prelims}
\subsection{Markov Random Field Models}\label{MRFs}
Consider univariate versions of the graph structure defined in Section \ref{motivation}, such that we have $n$ Gaussian nodes and $n$ binary nodes arranged on a lattice, with no edges connecting nodes of different types. Besag (1974) developed a class of auto-models, in which the probability distribution of each node conditional on all other nodes can be expressed as a one parameter exponential family. For a quantity at location $s_i$, a general form for the conditional distribution is
\begin{equation} \label{Besag}
f(x(s_i) | \boldsymbol{x}(\bar{s}_i) ) \propto \exp\left\lbrace A_i(\boldsymbol{x}(\bar{s}_i) )x(s_i)-B(\boldsymbol{x}(\bar{s}_i) + C_i(x(s_i))) \right\rbrace
\end{equation}
where $A_i(\boldsymbol{x}(\bar{s}_i) ) = \mu_i + \sum_{j\neq i}^{}\eta_{ij}x(s_j)$ is the natural parameter function and $B_i(\cdot)$ is a function of neighboring sites $\boldsymbol{x}(\bar{s}_i) $. The conditional mean is specified through $A_i$, where the explanatory variables $x(s_j)$ are themselves observations from the same process. The parameter $\mu_i$ controls the global mean structure of the model, and covariates are added to the model by setting $\mu_i = \boldsymbol{X_i}'\boldsymbol{\beta}$ for covariate vector $\boldsymbol{X_i} = \lbrack X_1(s_i),...,X_p(s_i)\rbrack'$ and regression parameter vector $\boldsymbol{\beta} = \lbrack\beta_1,...,\beta_p\rbrack'$. The term $\sum_{j\neq i}^{}\eta_{ij}x(s_j)$ is also known as the autocovariate or autoregression term, and controls the local mean structure through the dependence parameter(s), $\eta_{ij}$. Models deriving from Besag (1974) require a Markov assumption on the sites to ensure that joint distributions exist: for the neighborhood set $N_i$ at location $s_i$, $\eta_{ij} = 0$ if $s_j \notin N_i$, so that any two observations are conditionally independent if they are not in the same neighborhood.
%\medskip

For Gaussian nodes with global mean parameter $\mu_i$, the model in (\ref{Besag}) has specific form
\begin{equation*}\label{BesagZ}
f(z(s_i) | \boldsymbol{z}(\bar{s}_i)) = (2\pi\sigma^2)^{-1}\exp\left\lbrack \frac{-1}{2\sigma^2}\left(z(s_i) - \mu_i - \sum_{j\neq i}^{}\eta_{ij}z(s_j) \right)^2\right\rbrack
\end{equation*}
and for binary nodes with global mean parameter $\delta_i$, (\ref{Besag}) has specific form
\begin{equation*} \label{BesagY}
f(y(s_i) | \boldsymbol{y}(\bar{s}_i)) = \frac{\exp\left\lbrack y(s_i)(\delta_i + \sum_{j\neq i}^{}\eta_{ij}y(s_j))\right\rbrack}{1+\exp\left\lbrack\delta_i + \sum_{j\neq i}^{}\eta_{ij}y(s_j)\right\rbrack}
\end{equation*}
In both cases, if $\eta_{ij} = 0$ for all $i$ and $j$, the model reduces to the familiar Gaussian and logistic regressions at each node. 
%\medskip

Besag (1974) provides justifications for valid joint distributions for the auto-normal and auto-logistic models by deriving the parameter spaces that allow the joint distribution to be normalizable. Later work by Kaiser and Cressie (2000) provides a more general method for constructing valid joint distributions from conditionally-specified models and allows for extensions to more arbitrary neighborhood structures than in Besag (1974). After first specifying the distribution, neighborhood, and mean structure for each node individually, the conditional distributions are stitched together into a full joint distribution via restriction of the marginal supports. The converse of the conditional-specification method - in which we determine the model by first specifying a high-dimensional joint distribution, then derive the marginal or conditional distributions of the variables - is not straightforward nor intuitive in most cases. If we instead specify the conditionals and then derive the joint distribution, we need only to check two conditions to ensure a valid model.
%\medskip

To define the corresponding joint distribution from a set of conditionals, define the negpotential function as $\mathbf{Q(\boldsymbol{\utilde{x}})}\equiv \sum_{i=1}^{n}H_i(x(s_i)) + \sum\sum_{1\leq i < j \leq n} H_{ij}(x(s_i),x(s_j))$. For a pairwise Markov random field model, the $H$ functions are specified such that $\mathbf{Q(\boldsymbol{\utilde{x}})}$ looks like the exponentiated expression in (\ref{Besag}). Extending to larger neighborhoods (allowing for non-pairwise dependence), the negpotential function expands to $\mathbf{Q(\boldsymbol{\utilde{x}})}\equiv \sum_{i=1}^{n}H_i(x(s_i)) + \sum\sum_{1\leq i < j \leq n} H_{ij}(x(s_i),x(s_j)) + \sum\sum\sum_{1\leq i < j < k \leq n} H_{ijk}(x(s_i),x(s_j),x(s_k)) + ...$, with additional $H$ functions for each additional dimension of dependence. We consider only the simplest neighborhood structure for our model, but Kaiser and Cressie provide a flexible framework for specifying valid conditional models with more complex structure using the expansion of $\mathbf{Q(\boldsymbol{\utilde{x}})}$.

Using the negpotential function, Kaiser and Cressie (2000) define two conditions under which a conditionally-specified model corresponds to a valid joint distribution. The first condition is that the $H$ functions must be invariant to index permutation, a condition which generally holds for undirected graphical models with similar neighborhood structures for each node. The second condition requires the negpotential function to satisfy $\int_{\Omega}\exp\lbrack\mathbf{Q(t)}\rbrack dt < \infty$, where $\Omega$ is the support of the joint distribution of the variables $\boldsymbol{x}(s_i)$. This is essentially the statement that the distribution is normalizable, and requires restriction of parameter spaces such that the integral is finite. Provided its two conditions are met, Theorem 3 of Kaiser and Cressie (2000) leads to a valid full joint distribution as
\begin{equation*}
p(\boldsymbol{\utilde{x}}) = \frac{\exp\lbrack\mathbf{Q(\boldsymbol{\utilde{x}})}\rbrack}
{\int_\Omega \exp\lbrack\mathbf{Q(t)}\rbrack dt} \boldsymbol{.}
\end{equation*}
%2 key assumptions are required for this class of auto-models to be well-defined. The first- from Besag (1974)- is a Markov assumption with clique size of at most 2 locations (i.e., a pairwise dependence model). This implies that $x(s_i)$ depends conditionally on neighboring quantity $x(s_j)$ only through the dependence parameter $\eta_{ij}$, with no indirect influence by other quantities.  A second assumption is that the autoregressive function $\sum_{j=1}^{n}\eta_{ij}x(s_j)$ is a linear function of $x(s_i)$. 

\subsection{Mixed Multivariate Markov Random Fields} \label{MixedMRF}
The Markov random field model of Section \ref{MRFs} defines a spatial dependence structure for observations of the same type. We can extend that model to define a dependence structure for random variables of different types. Lee and Hastie (2015) consider a pairwise graphical model with node conditional distributions specified as Gaussian and logistic regressions. With mean parameters $\mu$ and $\delta$, and dependence parameters $\eta_z, \eta_y$, and $\rho$, these conditional distributions take the form
\begin{equation} \label{LHz}
 p(z(s_{i}) | \boldsymbol{z}(\bar{s}_i) , \boldsymbol{\utilde{y}}) = \frac{1}{\sqrt {2 \pi \sigma^2}} \exp\left\lbrace \frac{\ -\sigma^{-2}}{2} \left[ \frac{\mu_i + \sum_{i=1}^{n}\rho_{ij}y(s_j) + \sum_{i=1}^{n}\eta_{z,ij}z(s_j)}{\sigma^{-2}} - z(s_i) \right]^{2} \right\rbrace
\end{equation}
and
\begin{equation} \label{LHy}
p(y(s_{i}) | \boldsymbol{y}(\bar{s}_i) , \boldsymbol{\utilde{z}}) = \frac{\exp\left\lbrace y(s_i)\left(\delta_i + \sum_{i=1}^{n}\rho_{ij}z(s_j) +  \sum_{i=1}^{n}\eta_{y,ij}y(s_j) \right)\right\rbrace}
{1 + \exp\lbrace  y(s_i)\left(\delta_i + \sum_{i=1}^{n}\rho_{ij}z(s_j) +  \sum_{i=1}^{n}\eta_{y,ij}y(s_j) \right)\rbrace }  \textbf{.}
\end{equation}

The forms in (\ref{LHz}) and (\ref{LHy}) are extended from Section \ref{MRFs} with additional autoregressive parameters $\rho_{ij}$ for dependence between nodes of different types.
Equations (\ref{LHz}) and (\ref{LHy}) lead to a full joint distribution up to a normalizing constant. A form of this joint distribution adapted from Halsbeck and Waldorp (2015) is
\begin{multline} \label{LHjoint}
p(\boldsymbol{\utilde{y}},\boldsymbol{\utilde{z}} | \boldsymbol{\eta^y,\eta^z,\rho}) \propto
 \exp\lbrace \sum_{i=1}^{n}\lbrack\frac{-z(s_i)^2}{2\sigma^2} + \frac{\mu_i}{\sigma^2}z(s_i) + \delta_i y(s_i) \rbrack\\
  + \sum_{i=1}^{n}\sum_{j=1}^{n}\frac{1}{\sigma^2}\eta_{z,ij}z(s_i)z(s_j) + \sum_{i=1}^{n}\sum_{j=1}^{n}\eta_{y,ij}y(s_i)y(s_j) + \sum_{i=1}^{n}\sum_{j=1}^{n}\frac{\rho_{ij}}{\sigma^2}z(s_i)y(s_j) \rbrace \textbf{.}
 \end{multline}

Table 1 in Chen et al. (2014) provides restrictions for the parameters $\boldsymbol{\eta^y,\eta^z,\rho}$ that allow for valid joint distributions formed from conditional specifications from various one-parameter exponential family distributions, such as (\ref{LHjoint}). In particular, (\ref{LHjoint}) requires that the log-normalization term be finite so that the distribution is normalizable. For the model considered in this work, with only Gaussian and binary nodes, the only explicit restriction is that, for all $i$ and $j$, $\sum_{i=1}^{n}\eta^z_{ij}$ is small enough to ensure positive-definiteness of the Gaussian covariance matrix. In a four-nearest neighbor model, this constraint is $\sum_{i=1}^{n}\eta^z_{ij}<4$. There are no restrictions on the binary-binary or Gaussian-binary dependence parameters that would violate the log-normalization requirement above. For models with other types of mixed distributions (i.e., Poisson or gamma-family), details on necessary parameter space restrictions can be found in Yang, et al. (2014) or Chen, et al. (2014).
%\medskip

According to Chen, et al. (2014), a conditionally-specified graphical model as in (\ref{LHz}) and (\ref{LHy}) leads to a valid full joint distribution (\ref{LHjoint}) if and only if, for any $z(s_i)$ and/or $y(s_j)$, the conditional distributions for any set of nodes can be recovered from the full joint distribution. That is, using the definition of conditional probability,
\begin{equation}\label{LHcond}
p(y(s_{i}), z(s_{j}) | \boldsymbol{y}(\bar{s}_i) , \boldsymbol{z}(\bar{s}_j)) = \frac{p(\boldsymbol{\utilde{y}},\boldsymbol{\utilde{z}} | \boldsymbol{\eta_y,\eta_z,\rho})}
{\int p(\boldsymbol{\utilde{y}},\boldsymbol{\utilde{z}} | \boldsymbol{\eta_y,\eta_z,\rho}) dy(s_{i})dz(s_{j})} 
\end{equation}
holds for any choices of nodes $z(s_i)$ and/or $y(s_j)$. The condition in (\ref{LHcond}) is an adaptation (for mixed response distributions) of the previously discussed conditions from Kaiser and Cressie (2000). In both versions of conditionally-specified models, the primary challenge in proving the existence of a valid joint distribution is in determining the parameter spaces that allow for normalization.
%The requirement in (\ref{LHcond}) is equivalent to the conditions in Theorem 3 of (Kaiser and Cressie, 2000) for this model.
%\medskip


%which is just a generalization of the condition in (\ref{LHcond}) for specially constructed node-conditional distributions. In Section \ref{BivMMRF}, we show that both conditions from hold for the binary-Gaussian model.
%\paragraph{}
%While the framework of (Kaiser and Cressie, 2000) is not restricted to variables of similar distributions, all examples in that work are primarily concerned with quantities from the same type of distribution. Instead, we look to models for estimating the edge structure of undirected graphs with nodes of mixed distributions for specifying the node conditionals and parameter spaces.
%\medskip

 
\subsection{Centered Parameterizations for Markov Random Field Models} \label{Centered}
%\paragraph{}
The class of mixed Markov random field models described in Section \ref{MixedMRF} is primarily utilized to learn the structure of the graphical data using $n$ i.i.d. replicates of the multivariate model. In the bivariate mixed model of this work, the structure is considered fixed and known to a four-nearest neighbor model with one cross-dependence parameter, such that $\eta_{ij} = 0$ for $j \notin N_i$ and $\rho_{ij}=0$ for $i\neq j$, where $N_i$ is the neighborhood of location $s_i$. The primary focus here is on reliable inference on mean parameters and covariate effects that allow us to appropriately analyze a scientific question of interest. To do so, we want to re-parameterize the model in (\ref{LHz})-(\ref{LHjoint}) that allows us to separate the effects of mean structure from dependence structure.
%\medskip

As explained by Hughes and Haran (2010), the regression parameters original automodels from Section \ref{MRFs} are confounded and uninterpretable. The \textit{marginal} mean structures ($\mu_i$ and $\delta_i$) are not separated from the {conditional} autoregressive structures given through $\sum_{j=1}^{n}\eta_{ij}z(s_j)$ and $\sum_{j=1}^{n}\eta_{ij}y(s_j)$. Interpretation of $\eta_{ij}$ is thus difficult because we have not specified whether we are considering $\eta_{ij}$ \textit{after} or \textit{together} with the marginal mean parameters. For binary variables, dependence on neighboring values can only increase the conditional expectations for each node, an unfavorable characteristic for the model. Moreover, confounding also makes the dependence parameters $\eta_{ij}$ and the marginal mean parameters more difficult to consistently recover in the uncentered model, especially when the spatial dependence is non-negligible.

Kaiser, Caragea, and Furakawa (2012) proposed centered re-parameterizations of the univariate auto-models introduced in Section \ref{MRFs}, wherein the marginal mean structure is subtracted in the autocovariate. Define $\tau^{-1}_x(\cdot)$ as the function that maps expected values onto exponential family natural parameters, such that $\tau^{-1}_z(\mu_i)=\mu_i/\sigma^2$ and $\tau_y(\delta_i) = (\tau^{-1}_y(\delta_i))^{-1} = \frac{\exp(\delta_i)}{1+\exp(\delta_i)}$. For the univariate auto-normal and auto-logistic models respectively, the natural parameter functions $A_i(\cdot)$ then become
\begin{equation}\label{centerZ}
A_i(z(s_i)) = \tau^{-1}_z(\mu_i) + \sum_{j=1}^{n}\eta_{ij}\left(z(s_j)-\mu_j\right)
\end{equation} and
\begin{equation} \label{centerY}
A_i(y(s_i)) = \delta_i + \sum_{j=1}^{n}\eta_{ij}\left(y(s_j)-\tau_y(\delta_j)\right) .
\end{equation}
The centered re-parameterization alleviates the confounding and allows a convenient interpretation of the model parameters, because we have now isolated the marginal mean structure such that dependence parameters can only affect the covariance and conditional mean structure. For weak to moderate spatial dependence, we can interpret the parameters $\mu_i$ and $\delta_i$ as approximately reflecting the marginal or \textit{global} structure of the model, while the $\eta_{ij}$ parameters reflect the conditional or \textit{local} mean structure of the model. Behavior and interpretation under strong dependence is considered later.

\section{Properties of the Centered Bivariate Mixed MRF Model} \label{BivMMRF}
\subsection{Model Development} \label{ModelDef}
%The bivariate mixed Markov random field model builds on foundations in the previous sections. Recall the undirected bivariate graph structure from Section \ref{Structure}, where we have $n$ locations with 2 mixed nodes at each location connected by an edge, and a four-nearest neighbor edge structure among nodes of the same type. The Markov property as stated in the beginning of Section \ref{Centered} governs the conditional distribution of each node, and any two nodes are conditionally independent if they are not in the same neighborhood. For simplicity consider only an isotropic model ($\eta_{ij} = \eta$ and $\rho_{ij} = \rho$ for all $i,j$) and only interior locations (number of neighbors = $M = 4$ for all $i$). The latter 2 conditions are not necessary assumptions for a valid model, but allow us to simplify the scope of our investigation in this work. With these assumptions, we combine the mixed conditional distribution specification of (\ref{LHz}) and (\ref{LHy}) and the centered natural parameter functions of (\ref{centerZ}) and (\ref{centerY}), with an additional centering for the cross-dependence parameter $\rho$, and build the model from conditionally-specified distributions as in Kaiser and Cressie (2000).

In this section, we provide some technical developments of the model proposed in Section \ref{framework}. We developed this model for the specific bivariate graph structure with $n$ locations with 2 mixed nodes at each location connected by an edge, and a four-nearest neighbor edge structure among nodes of the same type. For simplicity, we consider only an isotropic model ($\eta_{ij} = \eta$ and $\rho_{ij} = \rho$ for all $i,j$) and only interior locations (number of neighbors = $M = 4$ for all $i$). The latter 2 conditions are not necessary assumptions for a valid model, but allow us to simplify the scope of our investigation in this work. We construct our model by building on the foundations outlined in Section \ref{prelims}.

Recall the conditional specification of the bivariate mixed Markov random field model from equations (\ref{condY})-(\ref{condZmean}).
For a binary node at location $s_i$, the conditional distribution is
\begin{equation*} \label{condY2}
p(y(s_{i})|\boldsymbol{y}(\bar{s}_i) , z(s_{i})) = \frac{\exp\left\lbrace y(s_i)\left(\phi(s_i)  \right)\right\rbrace}
{1 + \exp\lbrace y(s_i)\left(\phi(s_i) \right)\rbrace } 	
\end{equation*}
where
\begin{equation*} \label{condYmean2}
\phi(s_i) = \delta + \frac{\eta_{y}}{M} \sum_{j \in N_{i}} \left[y(s_j) - \frac{\exp(\delta)}{1+\exp(\delta)}\right] +\frac{\rho}{\sigma^2}(z(s_i) - \mu)  .
\end{equation*}

In the canonical exponential family form from (\ref{Besag}), this corresponds to 
\begin{math}
A_i\lbrace \boldsymbol{y}(\bar{s}_i), z(s_i) \rbrace =  \phi(s_i)
\end{math} and
\begin{math}
B_i\lbrace \boldsymbol{y}(\bar{s}_i), z(s_i) \rbrace = log \lbrack 1+ \exp\lbrace A_i\lbrace \boldsymbol{y}(\bar{s}_i), z(s_i) \rbrace\rbrace\rbrack
\end{math}. The conditional mean of $y(s_i)$ is then $E\lbrack y(s_{i})|\boldsymbol{y}(\bar{s}_i) , z(s_{i})\rbrack=\frac{\exp\left(\phi(s_i)\right)}
{1 + \exp\left(\phi(s_i) \right)}$. In (\ref{condYmean}), $M = 4$ is the number of neighbors of the same type for interior node $y(s_i)$ and $\boldsymbol{y}(\bar{s}_i)$ is the set of binary nodes at all locations $s_j$, $i\neq j$. As opposed to the models of Section \ref{MixedMRF}, here we divide our dependence parameter $\eta_y$ by the number of neighbors $M$ to allow for a convenient interpretation of the conditional mean as an average of neighboring values.

For a Gaussian node at location $s_i$, the conditional distribution is
\begin{equation*}\label{condZ2}
 p(z(s_{i}) | \boldsymbol{z}(\bar{s}_i) , y(s_{i})) = \frac{1}{\sqrt {2 \pi \sigma^2}} \exp\left\lbrace \frac{-1}{2\sigma^2} \left[z(s_i) - \alpha(s_i)  \right]^{2} \right\rbrace 
\end{equation*}
where
\begin{equation*}\label{condZmean2}
\alpha(s_i) =  \mu + \frac{\eta_z}{M} \sum_{j \in N_{i}} \left(z(s_j) - \mu\right)+ \rho\left(y(s_i) - \frac{\exp{(\delta)}}{1+\exp{(\delta)}}\right) .
\end{equation*}
Similar to (\ref{condYmean}), in (\ref{condZmean}) $M = 4$ is the number of neighbors of the same type for interior node $z(s_i)$ and $\boldsymbol{z}(\bar{s}_i)$ is the set of Gaussian nodes at all locations $s_j$, $i\neq j$. Under this parameterization, the conditional mean is $\alpha(s_i)$ and the conditional variance is $\sigma^2$. This is the "traditional" parameterization in terms of the conditional mean following from Besag (1974).

An alternative parameterization for the Gaussian nodes follows from Kaiser (2007) and Kaiser, Caragea, and Furukawa (2012). We can reparameterize the Gaussian nodes directly into natural exponential family form as in Section \ref{Centered}, such that the sufficient statistic is $z(s_i)$. Under this parameterization, the structure from (\ref{condZ}) corresponds to
\begin{math}
A_i\lbrace \boldsymbol{z}(\bar{s}_i), y(s_i) \rbrace =  \frac{\mu}{\sigma^2} + \frac{\eta_z}{M} \sum_{j \in N_{i}} \left(z(s_j) - \mu\right)+ \rho\left(y(s_i) - \frac{\exp{(\delta)}}{1+\exp{(\delta)}}\right)
\end{math} , 
\begin{math}
B_i\lbrace \boldsymbol{z}(\bar{s}_i), y(s_i) \rbrace =  (\sigma^2/2)A_i\lbrace \boldsymbol{z}(\bar{s}_i), y(s_i) \rbrace
\end{math}, and
\begin{math}
C_i (z(s_i)) =  \frac{-1}{2\sigma^2} z(s_i)^2 
\end{math}.
From this parameterization, the conditional mean of $z(s_i)$ is $E\lbrack z(s_{i})|\boldsymbol{z}(\bar{s}_i) , y(s_{i})\rbrack=\sigma^2 \lbrack A_i\lbrace \boldsymbol{z}(\bar{s}_i), y(s_i) \rbrace\rbrack$, and the conditional variance is $\sigma^2$ (assumed to be constant across locations). We refer to this parameterization in our discussion in Sections \ref{Centered} and \ref{breakdown} due to its connection to the centered parameterization literature as well as its use in Kaiser (2007). A resulting valid joint distribution is possible for either parameterization, but the induced covariance matrix does differ in each case. This leads to different parameter spaces for $\eta_z$ depending on the model: we need $\eta_{z} < 1$ in (\ref{condZ}), which we use in the following joint distribution, but $\eta_z<1/\sigma^2$ in the second parameterization. The resulting model for either parameterization is largely the same and produces generally similar results, but leads to different interpretations of $\eta_z$.
%\medskip

%Building on (\ref{condZ}) and (\ref{condY}) with the form in (\ref{LHjoint}), the joint conditional distribution for two mixed nodes at the same location $s_i$ is
%\begin{multline} \label{jointcond}
%p(y(s_i),z(s_i) | \textbf{y}(\bar{s}_i), \textbf{z}(\bar{s}_i)) \propto \\
%\exp\lbrace -\alpha(s_i) z(s_i)  - \frac{1}{2\sigma^2}z(s_i)^2 + \phi(s_i)y(s_i)  + \\
%\rho\left\lbrack \left( z(s_i)-\mu \right) (y(s_i) - \frac{\exp{(\delta)}}{1+\exp{(\delta)}}) %\right\rbrack \rbrace
%\end{multline} 

Stitching together the conditional distributions, we adapt the negpotential function for the full joint distribution for the centered bivariate Markov random field model from equation 7 in Lee and Hastie (2015):
\begin{multline} \label{fullneg}
\boldsymbol{Q(\utilde{y},\utilde{z})} = \sum_{i = 1}^{n} \left[\frac{\mu_i}{\sigma^2}z(s_i) - \frac{1}{2\sigma^2}z(s_i)^2 + \delta_i y(s_i)\right] +  \frac{\rho}{\sigma^2} \sum_{i = 1}^{n} \left[\left(z(s_i)-\mu_i\right)\left(y(s_i) - \frac{\exp{(\delta_i)}}{1+\exp{(\delta_i)}}\right)\right]\\
-\frac{1}{\sigma^2}\sum_{i=1}^{n}\sum_{j\in N_i}\left[ \frac{\eta_z}{M}\left( z(s_i)-\mu_i\right)\left(z(s_j)-\mu_j \right)\right]\\
 + \sum_{i=1}^{n}\sum_{j\in N_i}\left[\frac{\eta_y}{M}\left(y(s_i) - \frac{\exp{(\delta_i)}}{1+\exp{(\delta_i)}}\right) \left(y(s_j) - \frac{\exp{(\delta_j)}}{1+\exp{(\delta_j)}}\right)\right]
\end{multline}
The full joint probability distribution from (\ref{fulljointprop}) is
\begin{equation} \label{jointNeg}
p(\boldsymbol{\utilde{y},\utilde{z}}) = \frac{\exp(\boldsymbol{Q(\utilde{y},\utilde{z})})}{\int_{\Omega}\exp(\boldsymbol{Q(\utilde{y},\utilde{z})})d\boldsymbol{\utilde{y}}d\boldsymbol{\utilde{z}}}
\end{equation}
where $\Omega_{Y,Z} = \left\lbrace \lbrace0,1\rbrace \times \Re \right\rbrace$ is the full joint support. In accordance with the more flexible method of Kaiser and Cressie (2000) discussed in Section \ref{MRFs}, we could conceive a joint distribution for higher-order neighborhood structures by expanding (\ref{fullneg}) to include functions of three or more variables. The technical details of parameter space restrictions and centering that would enable a useful and interpretable higher-order model are an avenue for further work.

It remains to show that the full joint distribution is valid. It is clear that our $H$ functions that define the negpotential function are not affected by permutation of indices, because clique size is restricted to 2 in this case and the model is only centered based on the marginal mean at the specific node. When generalizing beyond pairwise-only dependence to irregular and/or anisotropic structures, the permutation condition is not necessarily met and requires careful consideration. Using the definition of conditional probability and some calculus, it is possible to show that the requirement in (\ref{LHcond}) and thus also Theorem 3 of Kaiser and Cressie (2000) holds for this model, so that $\exp\lbrace \boldsymbol{Q(\utilde{y},\utilde{z})}\rbrace$ is a valid generating function.

A more involved proof of the validity of the joint distribution- requiring us to show that the denominator in (\ref{jointNeg}) is finite- is based on the proof for (\ref{LHjoint}) from Chen et al. (2014). One important key in that proof is that the distribution of the Gaussian variables when conditioned on the binary variables is a Gaussian Markov random field. This holds for both the parameterization from Lee and Hastie (2015) (see equations 4-6) and the slightly different parameterization of Halsbeck and Waldorp (2015). We provide the details in Appendix \ref{JointProof}.


\subsection{Mean Structures and Covariate Relationships} \label{ModelProp}
Using the model specification in (\ref{condY}) and (\ref{condZ}), the \textit{conditional} (local) mean structure is determined by the parameter functions $\phi(s_i)$ and $\alpha(s_i)$. In accordance with the centering ideas of Section \ref{Centered}, the \textit{marginal} (global) mean structure is reflected in parameters $\mu$ and $\delta$ for cases where the dependence is not too strong. The univariate spatial dependence parameters $\eta$ and cross-dependence parameter $\rho$ only determine the covariance structure and local expectations of the model, so that we can more reliably estimate both the marginal mean structure and spatial structure.
%\medskip

To create a model with non-constant global mean, we can add covariate information to the global structure. Let $\mu_i = \boldsymbol{X_{z_i}'\beta_z}$ and $\delta_i = \boldsymbol{X_{y_i}'\beta_y}$ where $\boldsymbol{X_{z_i}}$ and $\boldsymbol{X_{y_i}}$ are respective $p$ x $1$ covariate vectors for $z(s_i)$ and $y(s_i)$,  with $p$ x $1$ regression parameter vectors $\boldsymbol{\beta_z}$ and $\boldsymbol{\beta_y}$. The covariate matrices need not be distinct, $\boldsymbol{X_{z_i}}$ and $\boldsymbol{X_{y_i}}$ may contain the same columns if the analyst would like to investigate a set of covariates in relation to both response variables. The $\boldsymbol{X\beta}$ structure governs the large-scale behavior of the model, thus the dependence parameters $\eta_y$, $\eta_z$, and $\rho$ account for additional variation in the responses due to local behavior. We can further characterize the parameters by noting that, in (\ref{condY}) and (\ref{condZ}), when $\rho=0$ the model reduces to two separate univariate autoregression models. When we additionally remove the spatial dependence by setting $\eta_{y}=\eta_z=0$, the model reduces to familiar linear and logistic regressions at each node with no effects from local variation.

An alternative to the bivariate spatial model is to consider two univariate spatial regression models, one for each distribution type. The relationship between $\boldsymbol{y}$ and $\boldsymbol{z}$ could then be modeled as a covariate in each regression, by including $\boldsymbol{y}$ as a covariate in the $\mathbf{X_z}\boldsymbol{\beta_z}$ structure and vice versa. A particular advantage of the bivariate model is that it takes advantage of knowledge about the spatial structure in the joint likelihood while estimating the relationship between response variables. Investigations with simulated data show that when the spatial dependence is relatively weak, two univariate models are still able to model the covariate and dependence relationships reasonably well (that is, unbiased and efficient) when compared to the more complicated bivariate model. For larger values of $\eta_y$ and $\eta_z$, only the bivariate model can effectively capture both the covariate and dependence relationships present in the data.

\subsection{Model Breakdown} \label{breakdown}
Several mentions of \textit{strong} and \textit{weak} spatial dependence have been made thus far without quantifying or defining what the terms actually mean. A discussion of what constitutes strong dependence and how it affects the properties of the bivariate mixed model follows.
%\medskip

Even when the model parameters are within the appropriate parameter space to define a valid joint distribution, the convenient interpretation of marginal and conditional expectations as in Section \ref{Centered} depends on the ability to discern between global and local structure. When the dependence is strong, the effect of the local structure through the autocovariate $\eta$ overwhelms the effect of the global structure in $\boldsymbol{X\beta}$. The observed marginal mean of the response values is a reflection of neighboring values rather than global mean structure, thus estimation of the global regression parameter vector $\boldsymbol{\beta}$ is difficult. With this in mind, we can define \textit{strong} dependence as the values of $\eta_y$, $\eta_z$, and $\rho$ such that the marginal expectations under dependence are no longer approximately the same as those under independence ($\eta_y$ = $\eta_z$ = $\rho$ = 0).
%\medskip

Define the upper bound for a dependence parameter to be the smallest (in absolute value) value of $\eta_y$, $\eta_z$, and $\rho$ such that the marginal expectations under dependence are approximately equal to the marginal expectations under independence. Kaiser (2007) proposed that the upper bound for a univariate model could be determined as
\begin{equation} \label{upperbound}
|\eta| \leq \left\lbrack \sup_{\tau(A_i)\in\Theta}\frac{\tau(A_i) - \kappa_i}{A_i - \tau^{-1}(\kappa_i)} \right\rbrack^{-1}
\end{equation}
\begin{figure}[t]
	\centering
	\includegraphics[scale=0.35]{images/etayub2.pdf}
	\caption[Standard Upper Bounds for Autologistic Dependence Parameter]{Upper Bounds for $\eta_y$ vs. $\delta_i$ as reproduced from Kaiser (2007)}
	\label{etaUB}
\end{figure}
where $\tau$ and $A_i$ are as in (\ref{centerZ}) and (\ref{centerY}) of Section \ref{Centered},  $\kappa_i = \mu_i$ or $\delta_i$ depending on the model, and $\Theta$ is the range of possible values for the conditional expectations. For Gaussian auto-models, Kaiser plugs in the natural parameters and link functions on the right hand side of (\ref{upperbound}) to get the upper bound for $\eta_z$ as $1/\sigma^2$. Using the Gaussian parameterization of the same model as in (\ref{condZ}), this would correspond to an upper bound of 1. For binary univariate models, the bound must be estimated numerically and depends on the value of $\delta_i$. The smallest upper bound for a four-nearest neighbor model is $|\eta_y| = 4$ when $\delta_i = 0$, with the bound increasing symmetrically as $\delta_i$ gets further from 0. A plot of these upper bounds is provided in Figure \ref{etaUB}. With $\rho=0$, binary data generated from the model (\ref{condY}) tends to toward a field of all 0s or 1s as $\eta_y$ goes beyond its upper bound.
%\medskip

The upper bounds for $\eta_y$ and $\eta_z$ as derived from Kaiser (2007) provide suitable starting point limitations for the dependence parameters in the bivariate mixed MRF model. When $\rho \neq 0$, the upper bounds of $\eta_z = 1$ and $\eta_y = 4$ are too large. When generating data from the bivariate model, the cross-dependence can effectively "transmit" the spatial dependence from the Gaussian field to the binary field or vice versa. Hardouin and Cressie (2018) use the term "reinforce" when referring to the connected spatial dependence in their bivariate model.  A suitably large combination of $\rho$ and $\eta_{z}$ could cause the generated binary data to be far from its true marginal expectations, even if $\eta_y$ is near 0 (i.e., no spatial dependence among binary nodes). As a result, we need suitable upper bounds for $\rho$ and $\eta$s \textit{together} in order to determine if the proposed model is viable for inference in a particular dataset.
%\medskip

One suggestion is to consider the nodes together in an isotropic model as in Section 7 of Kaiser (2007), which would suggest bounds of $|\eta_z| + |\rho/\sigma^2| \leq 1$ or $|\eta_y| + |\rho/\sigma^2| \leq 4$. Under spatial independence ($\eta_z=\eta_y=0$) the bounds for $\rho$ would typically not agree, with one being too small and the other too large. We note that the Gaussian upper bound is determined by the necessity of a positive definite covariance matrix, which is unaffected by $\rho$ in the model specification in (\ref{condZmean}) with only one cross-dependent neighbor. However, the binary upper bound is determined through the conditional mean specification, and thus we might consider taking $|\eta_y| + |\rho/\sigma^2| \leq 4$ as the very conservative upper bound for $\rho$. Unfortunately, our simulations often produced degenerate data well before this boundary was reached, thus it appears be too conservative for any practical use. 

The preceding discussion is intended to provide caution about interpretation and estimation of model parameters in the presence of strong dependence. The difficulties in deriving a reasonable upper bound are due to the differences in scale and support for Gaussian and binary distributions. Moreover, degenerate auto-normal models and degenerate auto-logistic models do not behave in similar ways under strong dependence. A careful analytical derivation of upper bounds in multivariate models is an avenue for future work. We relegate some speculative initial discussion to Appendix \ref{specUB}. %One speculative but not rigorously investigated proposal for an upper bound is outlined in Appendix \ref{specUB}. What we can conclude from the preceding discussion is that bivariate models can degenerate even if the univariate dependence parameters are not too strong. Considerable caution should be taken to ensure the bivariate mixed model can be applied appropriately in a particular situation.

\section{Estimation and Inference} \label{EstimInf}
\subsection{Likelihood-based Estimation} \label{MLEest}
In this work we consider the estimation of model parameters via maximum pseudo-likelihood. Alternative Bayesian estimation methods exist, such as using an auxillary spatial field in the prior as in Sun and Clayton (2008) or Liang (2010). We prefer the traditional maximum pseudo-likelihood estimation here due to relatively simple implementation and faster computation.
%\medskip

Estimates of the parameters can be found by maximizing the full log-likelihood or minimizing the negative of the log-likelihood $\boldsymbol{\ell}$, given by
\begin{equation} \label{fullLogLik}
\boldsymbol{\ell} = \log\sum_{i=1}^{n} \lbrace\boldsymbol{Q(\utilde{y},\utilde{z})} - \log\boldsymbol{D(\utilde{y},\utilde{z}},\eta_z,\eta_y,\rho)\rbrace
\end{equation}
where $\boldsymbol{Q(\utilde{y},\utilde{z})}$ is the negpotential function from (\ref{fullneg}) and $\boldsymbol{D(\cdot)}$ is the normalizing constant from the denominator in (\ref{jointNeg}). The form of $\boldsymbol{D(\cdot)}$ requires a high-dimensional integral for estimation, and is intractable for more than a few locations. To avoid computation issues with the normalizing constant, Besag (1975) instead proposed maximum pseudo-likelihood estimation (MPLE), in which we may take advantage of the conditional specification of the model. Instead of using the full log-likelihood, we consider the likelihood of each individual node as a separate regression model and then stitch together each conditional distribution into a pseudo-likelihood, which is then maximized to obtain parameter estimates. The log-pseudo-likelihood to maximize is given by
\begin{equation}\label{logplik}
\tilde{\boldsymbol{\ell}} = \log\left(\sum_{i=1}^{n} \lbrace{p(z(s_{i}) | \boldsymbol{z}(\bar{s}_i) , y(s_{i}))}\rbrace\right) + \log\left(\sum_{i=1}^{n} \lbrace{p(y(s_{i}) | \boldsymbol{y}(\bar{s}_i), z(s_{i}))}\rbrace\right)
\end{equation}
where $p(z(s_{i}) | \boldsymbol{z}(\bar{s}_i) , y(s_{i}))$ and $p(y(s_{i}) | \boldsymbol{y}(\bar{s}_i), z(s_{i}))$ are the node-conditional distributions from (\ref{condY}) and (\ref{condZ}). While there is some loss in efficiency because the MPLE is not the same as the full likelihood, Hughes et al. (2011) show that the loss is small for large lattices. When the number of sites is small, the estimates for both MLE and MPLE are typically so inaccurate that efficiency is not the primary concern.
\subsection{Simulation and Inference}
\label{SimInf}
Simulated realizations of mixed Markov random fields are useful for various inference and model assessment procedures. Conveniently, the specification of conditional distributions allows a ready implementation of a Gibbs sampling procedure. The procedure generates realizations of a bivariate MRF by simulating from the node-conditional distributions and iterating until convergence, then keeping samples from the Markov chain. For pre-specified parameter set $\boldsymbol{\Theta} = (\mu,\delta,\sigma^2,\eta_z,\eta_y,\rho)$ and $n$ locations ($2n$ total nodes) for the model in Section \ref{BivMMRF}, the simulation procedure to generate $M$ independent samples is as follows:
\begin{enumerate}
	\item Generate $n$ x $1$ vectors of starting values $\boldsymbol{\utilde{y}^{(0)}} \sim Ber(\frac{\exp{(\delta)}}{1+\exp{(\delta)}})$ and $\boldsymbol{\utilde{z}^{(0)}} \sim N(\mu, \sigma^2)$ for locations $s(i)$, $i=1,...,n$.
	\item For $j=1,...,B+M\cdot S$:
	\begin{enumerate}[label=(\alph*)]
	\item For locations $i=1,...,N$:
	\begin{itemize}
	\item Generate a new vector of binary values $\boldsymbol{\utilde{y}^{(j+1)}} = \lbrace y^{(j+1)}(s_i):i=1,...,n\rbrace$ by generating from the node-conditional distributions, a simulation from the distribution in (\ref{condY}):\\ $p(y^{(j+1)}(s_{i})|\boldsymbol{y}^{(j)}(\bar{s}_i), z^{(j)}(s_{i}))$, where\\ $\boldsymbol{y}^{(j)}(\bar{s}_i) = \lbrace y^{(j+1)}(s_k): k= 1,...,i-1\rbrace\cap \lbrace y^{(j)}(s_q): q= i+1,...,n\rbrace$
		\end{itemize}
	\item For locations $i=1,...,N$:
	\begin{itemize}
	\item Generate a new vector of Gaussian node values $\boldsymbol{\utilde{z}^{(j+1)}} = \lbrace z^{(j+1)}(s_i):i=1,...,n\rbrace$ by generating from the node-conditional distributions, a simulation from the distribution in (\ref{condZ}):\\
	$p(z^{(j+1)}(s_{i})|\boldsymbol{z}^{(j)}(\bar{s}_i) , y^{(j+1)}(s_{i}))$, where\\ $\boldsymbol{z}^{(j)}(\bar{s}_i) = \lbrace z^{(j+1)}(s_k): k= 1,...,i-1\rbrace\cap \lbrace z^{(j)}(s_q): q= i+1,...,n\rbrace$
	\end{itemize}
\end{enumerate}
\item For $j > B$, keep every $S$th collection of observations $\lbrace\boldsymbol{\utilde{y}^{(j)}}, \boldsymbol{\utilde{z}^{(j)}}\rbrace$, discarding others, until desired sample size $M\geq1$ is reached.

\end{enumerate}
Here $B$ is the number of iterations needed for convergence, varying on starting values and lattice size. For a 30 x 30 lattice, $B=150$ is reasonable but little time is lost in increasing $B$ to 500 or more to ensure convergence. Likewise for the thinning value, $S=10$ works well but little time is lost in increasing to $S\geq 50$ to ensure independence between simulations. Examination of the autocorrelations between samples for simulated data in Section \ref{SimStudy} indicated no concerns about independence for $S\geq10$ for the schemes used.
%\medskip

As in Caragea and Berg (2014), we obtain measures of uncertainty about parameter estimates for the bivariate mixed Markov random field model via parametric bootstrap. Given maximum pseudo-likelihood estimates $\hat{\boldsymbol{\Theta}}$ as starting values, we generate bootstrap samples by keeping every $S$th simulated dataset after an initial burn-in size of $B$, until a suitable bootstrap sample size $R$ is obtained for reliable inference. Here we need $B$ large enough to ensure convergence of the first replicate we keep, and we need $S$ large enough to ensure independence between samples.
%\medskip

For each of the $R$ bootstrap replicates, we obtain MPLE estimates and use the percentiles of the resulting empirical distribution to obtain confidence intervals for model parameters. We use a basic bootstrap comparison function to ensure the intervals do not depend on the unknown model parameters. The lower and upper bounds for the $100(1-\alpha)\%$ bootstrap confidence intervals are $L_\alpha = 2\hat{\theta} - \theta^*_{1-\alpha/2}$  and  $U_\alpha = 2\hat{\theta} - \theta^*_{\alpha/2}$,
where $\hat{\theta}$ is the initial MPLE of parameter $\theta\in\boldsymbol{\Theta}$ over the data and $\theta^*_q$ is the quantile of the corresponding bootstrap empirical distribution of $\theta$. In Section \ref{CISIM}, we investigate the empirical coverage of the basic parametric bootstrap under different model parameter conditions.

Alternatives to the basic parametric bootstrap exist. One example is the simple percentile bootstrap, in which we only take the percentiles of the empirical distribution as our bounds. Based on exploratory simulations, we found that the percentile bootstrap tends to give confidence intervals that are much too wide. A normal confidence interval based on large sample properties of the likelihood estimates and the Fisher information matrix is not easily derived from the pseudo-likelihoods. Hughes, et al. (2010) show how to estimate the necessary information for a higher-dimensional approximation to the full likelihood in a univariate autologistic model, although this is much more computationally demanding. Another consideration to improve efficiency would be the double bootstrap, in which the standard error is estimated by bootstrapping each initial bootstrap estimate. Implementing such a procedure in any practical scenario would be prohibitively expensive due to computation time. As we will illustrate in Section \ref{CISIM}, the basic bootstrap coverage is reasonably close to the nominal coverage and there is not much efficiency to be gained.
\subsection{Model Assessment} \label{ModCRPS}
In addition to the typical measures of model goodness-of-fit, we use the estimated conditional distribution of each node to compare the \textit{in-sample} fit of various models. The continuous ranked probability score (Gneiting and Raftery (2007)) can be used to assess the sharpness (precision) and calibration (bias) of a probabilistic forecast.  When comparing the fit of several models, the model that minimizes average CRPS over the data is considered "best". The CRPS is computed based on conditonal distributions, hence it reflects how well the model fits the (conditionally-specified) spatial structure of a given model. The CRPS is a generalization of the Brier score that is illustrated in Caragea and Berg (2014).

For a node $x(s_i)$ with conditional cumulative distribution function $F(x(s_i)|\boldsymbol{x}(\bar{s_i}), \boldsymbol{\Theta})$, and an observation $x_i$ the CRPS is given by
\begin{equation} \label{CRPS}
CRPS(F(x(s_i)|\boldsymbol{x}(\bar{s_i}), \boldsymbol{\Theta}), x_i) = \int_{-\infty}^{\infty}(F(x(s_i)) - \mathbbm{1}_{\lbrack x_i,\infty)}(t))^2 dx(s_i)
\end{equation}
For a specified model, each of $n$ Gaussian nodes has a unique conditional CDF $F(\cdot)$ from a Gaussian distribution as in (\ref{condZ}), and each of $n$ binary nodes has a unique conditional CDF $F(\cdot)$ from a Bernoulli distribution as in (\ref{condY}). With our observed data, we calculate the CRPS for each node and then take the average to obtain a measure of in-sample model fit. For some classes of distributions the integral in (\ref{CRPS}) is difficult to evaluate analytically or numerically, however for only binary and Gaussian conditionals the form is well-known and can be evaluated quickly using the \texttt{scoringRules} package in \texttt{R} (Jordan, et al. (2017)).
%\medskip

The CRPS is often modified into a "skill score", in which the model's fit is compared to the performance of a reference model. The skill of a model is defined as
\begin{equation}
Skill = 100 \cdot \left\lbrack 1 - \frac{CRPS(M)}{CRPS(c)}\right\rbrack
\end{equation}
where $CRPS(M)$ is the mean CRPS of the model over all points as above, and $CRPS(c)$ is the score of a constant mean model where every observation is predicted to be the sample mean. For other scenarios, it may be necessary to use a different reference model as the baseline. The skill of the model is between 0 to 100 and is the percent improvement in a model over the constant model. The optimal model is then the model that maximizes the skill.

\section{Simulation Study}\label{SimStudy}
\subsection{Parameter Estimation} \label{ParEstSim}
The efficiency of the maximum pseudo-likelihood estimation procedure from Section \ref{EstimInf} varies based on the model, lattice size, and especially strength of the dependence, and we investigate the latter here. In this study, we simulate data for 3 different combinations of dependence. We compare estimates for the full bivariate mixed model to reduced models on a 30 x 30 square lattice. The reduced models are univariate spatial and non-spatial models, as well as bivariate models without covariates or spatial parameters. The three combinations of dependence parameters ($\rho$, $\eta_y$, $\eta_z$) are given in Table 1 and correspond to weak, moderate, and strong dependence, respectively. In particular, the "strong" dependence combination is close to the edge of the well-behaved parameter spaces discussed in Section \ref{breakdown}.

For the univariate models, the opposite response variable is included as a centered covariate (i.e., in the $\boldsymbol{X\beta}$ structure) rather than in the autocovariate (dependence structure), and the estimate of cross-correlation $\rho$ is based on the regression coefficient for the centered binary variable covariate in the univariate Gaussian-response model. The motivation for this approach in the separate univariate models is that, in some practical situations (i.e., observational studies rather than designed experiments), we might prefer not to ignore available information on the other response variable. Even if we had no knowledge on how to model the variables in a dependence structure as introduced here, we might still wish to take advantage of the relationship between the two variables.

Additionally, we include 2 covariates (one for each response variable) in the model as an illustration of the flexible modeling capabilities for the bivariate mixed MRF model. The covariate for the binary response is a normal random variable with visible spatial correlation  generated using the simulation algorithm from Section \ref{SimInf} (with $\eta_z=0.9$, $\mu=1$, $\sigma^2=1$), and the covariate for the Gaussian response is a randomly generated $Gamma(3,4)$ random variable with no spatial correlation. Images of the covariates used are presented in Figure \ref{covariateIMG}. We keep the corresponding regression coefficients ($\beta_{1,y}, \beta_{1,z}$), intercepts ($\beta_{0,y}, \beta_{0,z}$) and variance ($\sigma^2$) constant across the 3 combinations of dependence parameters.
\begin{figure}[t] 
\centering
	\begin{subfigure}{0.4\textwidth}
		\centering
	\includegraphics[width=\textwidth]{images/ycovsim.pdf}
	\end{subfigure}
	\begin{subfigure}{0.4\textwidth}
		\centering
	\includegraphics[width=\textwidth]{images/zcovsim.pdf}
	\end{subfigure}
\caption[Covariates Used in Estimation Procedure Study]{Covariates used to simulate data. The covariate for the binary variable (left) exhibits a slight trend and weak spatial dependence.}
\label{covariateIMG}
\end{figure}
\begin{table}[!h]
	\centering
	\begin{tabular}{|p{2.5cm}||p{1cm}||p{1cm}||p{1cm}||p{1cm}||p{1cm}||p{1cm}||p{1cm}||p{1cm}|}
		\hline
		\multicolumn{9}{|c|}{\textbf{Parameter Regimes Used to Simulate Data}} \\
		\hline
		\textbf{Dependence} & \textbf{$\rho$}& \textbf{$\eta_z$} & \textbf{$\eta_y$}& \textbf{$\beta_{0y}$}& \textbf{$\beta_{1y}$}& \textbf{$\beta_{0z}$}& \textbf{$\beta_{1z}$}& \textbf{$\sigma^2$}\\
		\hline
		Weak & 0.2   &  0.3 & 1 & -1 & 0.5 & 1 & 0.5 & 1\\
		\hline
		Moderate & 1   &  0.3 & 1 & -1 & 0.5 & 1 & 0.5 & 1\\
		\hline
		Strong & 0.5   &  0.9 & 3.5 & -1 & 0.5 & 1 & 0.5 & 1\\
		\hline
	\end{tabular}\\
	\begin{tabular}{ |p{2.5cm}||p{1cm}||p{1cm}||p{1cm}||p{1cm}||p{1cm}||p{1cm}||p{1cm}||p{1cm}|}
		\hline
		\multicolumn{9}{|c|}{\textbf{Models}} \\
		\hline
		\textbf{Model} & \textbf{$\rho$}& \textbf{$\eta_z$} & \textbf{$\eta_y$}& \textbf{$\beta_{0y}$}& \textbf{$\beta_{y1}$}& \textbf{$\beta_{z0}$}& \textbf{$\beta_{z1}$}& \textbf{$\sigma^2$}\\
		\hline
		Full (1) & \checkmark   &  \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark\\
		\hline
		Constant Mean (2) & \checkmark   &  \checkmark & \checkmark & \checkmark & x & x & \checkmark & \checkmark\\
		\hline
		Univariate Spatial (3) & *   &  \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark\\
		\hline
		Univariate Non-Spatial (4) & *  &  x & x & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark\\
		\hline
		Bivariate Non-Spatial (5) & \checkmark   &  x & x & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark\\
		\hline
	\end{tabular}\\
	\caption{Parameter sets and reduced models compared in the simulation study.}
	\label{parameters}
\end{table}
For each combination of parameters in Table \ref{parameters},  we simulated 1000 data sets and  obtained maximum pseudo-likelihood estimates of the parameters for each of the 5 models. Summaries of bias, percent bias, and standard errors of the parameter estimates are available in Table 2. Boxplots of the estimates are available in Figures \ref{spatests} and \ref{meanests}.

Estimates of the dependence parameters in Figure \ref{spatests} show that for the "weak" dependence combination, estimates from the reduced models are still approximately unbiased for $\eta_z$ and $\eta_y$. As the dependence strength increases, only the full model is able capture all of the dependence structure effectively. The univariate models (M3 and M4) are able to capture some of the cross-dependence $\rho$ without the autocovariate structure at weaker levels of dependence, although the cost is more uncertainty in estimates of the other dependence parameters $\eta_y$ and $\eta_z$. This provides evidence that the more complex full bivariate mixed model is most appropriate when the total spatial dependence (combined $\rho$, $\eta_y$, and $\eta_z$) is strong, but may not be necessary under weaker dependence regimes. Moreover, the inability of the constant mean model (M2) to capture spatial dependence indicates the need to first correctly specify the global structure through covariates before any attempt at unbiased estimation or inference on the dependence parameters is possible. As one might expect, the variance parameter $\sigma^2$ is smallest for the full model in all regimes, and is also the closest to the true simulated value of 1.

Estimates of the regression coefficients (Figure \ref{meanests}) indicate that under weak dependence regimes, the simpler models perform almost as well as the full model. Intuitively, the simpler models can only account for variability due to spatial dependence by adding uncertainty to the covariate structure and process variance ($\sigma^2$). When the dependence is weak, there is less variation due to dependence that causes bias in the estimates of covariates. From the top panel in Table \ref{EstResults}, we conclude that there is little to no gain in efficiency in using the full bivariate model over simpler models when the dependence is weak.

For the strongest combination (far right in Figure \ref{meanests}), none of the models effectively capture the intercepts, and only the bivariate models (M1 and M5) are able to capture the covariate relationships in $\beta_{1y}$ and $\beta_{1z}$ (even if unreliably). Because the "strong" dependence regime is beyond the limits of what we would consider a nicely-behaved model, the simulated data reflect local structure rather than global structure. The observed data does not accurately reflect the covariate relationships and expected marginal mean structure because it is overwhelmed by local spatial effects, thus we would not expect any model to effectively estimate those parameters. Figure \ref{meanests} indicates that our best hope is to use a bivariate model that accounts for as much of the local dependence is possible. Even under the moderate regime (middle column) there is a clear advantage for the bivariate models over the univariate models when attempting to estimate covariate relationships.

\begin{sidewaystable}
	\begin{table}[H]
		%\begin{small}
		%\resizebox{\textwidth}{!}{
		\resizebox{\textwidth}{2.5in}{
			\begin{tabular}{|c||c||c||c||c||c||c||c||c||c|}
				%\hline
				%\multicolumn{9}{|c|}{\textbf{Maximum Pseudo-likelihood Estimates}} \\
				\hline
				\multicolumn{10}{|c|}{} \\
				\multicolumn{10}{|c|}{\textbf{Weak}} \\
				\hline
				\textbf{Model} &\textbf{Estimate} & \textbf{$\rho$}& \textbf{$\eta_z$} & \textbf{$\eta_y$}& \textbf{$\beta_{0y}$}& \textbf{$\beta_{1y}$}& \textbf{$\beta_{0z}$}& \textbf{$\beta_{1z}$}& \textbf{$\sigma^2$}\\
				\hline
				\centering
				1 &Bias[\%] & 0.0062 [3.1\%] & 0.0017 [0.57\%] & 0.0727 [7.27\%] & -0.0104 [1.04\%] & 0.0123 [2.46\%] & 0.006 [0.6\%] & -3e-04 [-0.3\%] & -0.0032 [-0.32\%] \\  
				&SE & (0.087) & (0.094) & (0.505) & (0.105) & (0.073) & (0.081) & (0.005) & (0.053) \\ 
				\hline
				2 &Bias[\%]& -0.0002 [-0.1\%] & -0.1027 [-34.23\%] & 0.4093 [40.93\%] & 0.1856 [-18.56\%] & - & 1.2606 [126.06\%] & - & 0.4841 [48.41\%] \\ 
				& SE& (0.094) & (0.093) & (0.438) & (0.089) &  & (0.041) &  & (0.072) \\ 
				\hline
				3 &Bias[\%]& 0.3475 [173.75\%] & 0.0029 [0.97\%] & -0.0088 [-0.88\%] & -0.0018 [0.18\%] & 0.004 [0.8\%] & 0.0023 [0.23\%] & -0.0001 [-0.1\%] & 0.003 [0.3\%] \\
				&SE& (0.254) & (0.093) & (0.49) & (0.098) & (0.071) & (0.077) & (0.005) & (0.052) \\ \hline
				4 &Bias[\%]& - & - & - & 0.0141 [-1.41\%] & -0.0018 [-0.36\%] & 0.0016 [0.16\%] & -.0001 [-0.1\%] & 0.0295 [2.95\%] \\ 
				&SE&  & &  & (0.096) & (0.07) & (0.077) & (0.005) & (0.053) \\  \hline
				5 &Bias[\%& 0.0123 [6.15\%] & - & - & 0.0033 [-0.33\%] & 0.0035 [0.7\%] & 0.0018 [0.18\%] & -0.0001 [-0.1\%] & 0.0194 [1.94\%] \\
				&SE & (0.089) &  &  & (0.098) & (0.07) & (0.077) & (0.005) & (0.053)\\ 
				\hline
				\multicolumn{10}{|c|}{} \\
				\multicolumn{10}{|c|}{\textbf{Moderate}} \\
				\hline
				\textbf{Model} &\textbf{Estimate} & \textbf{$\rho$}& \textbf{$\eta_z$} & \textbf{$\eta_y$}& \textbf{$\beta_{0y}$}& \textbf{$\beta_{1y}$}& \textbf{$\beta_{0z}$}& \textbf{$\beta_{1z}$}& \textbf{$\sigma^2$}\\
				\hline
				1 &Bias[\%] & 0.012 [1.2\%] & -0.001 [-0.33\%] & 0.171 [17.1\%] & 0.093 [-9.3\%] & 0.011 [2.2\%] & 0.055 [5.5\%] & 0 [0\%] & 0.001 [0.1\%] \\ 
				&SE& (0.077) & (0.085) & (0.52) & (0.253) & (0.079) & (0.138) & (0.006) & (0.052) \\  \hline
				2 &Bias[\%]& -0.04 [-4\%] & -0.089 [-29.67\%] & 0.391 [39.1\%] & 0.254 [-25.4\%] & -  & 1.284 [128.4\%] & - & 0.505 [50.5\%] \\ 
				& SE& (0.089) & (0.082) & (0.433) & (0.133) & & (0.06) & & (0.072) \\   
				\hline
				3 &Bias[\%]& 0.329 [32.9\%] & 0.099 [33\%] & 0.305 [30.5\%] & 0.287 [-28.7\%] & -0.108 [-21.6\%] & 0.074 [7.4\%] & 0 [0\%] & 0.216 [21.6\%] \\ 
				&SE& (0.185) & (0.089) & (0.452) & (0.096) & (0.069) & (0.093) & (0.006) & (0.061) \\\hline
				4 &Bias[\%]& - & - & -& 0.309 [-30.9\%] & -0.12 [-24\%] & 0.076 [7.6\%] & 0.0000 [0\%] & 0.272 [27.2\%] \\ 
				&SE& & & & (0.091) & (0.067) & (0.091) & (0.006) & (0.063) \\  \hline
				5 &Bias[\%] & 0.056 [5.6\%] & - & - & 0.102 [-10.2\%] & -0.003 [-0.6\%] & 0.047 [4.7\%] & 0.003 [0\%] & 0.028 [2.8\%] \\ 
				&SE & (0.078) & & & (0.128) & (0.076) & (0.095) & (0.006) & (0.052) \\  
				\hline
				\multicolumn{10}{|c|}{} \\
				\multicolumn{10}{|c|}{\textbf{Strong}} \\
				\hline
				\textbf{Model} & \textbf{Estimate} &\textbf{$\rho$}& \textbf{$\eta_z$} & \textbf{$\eta_y$}& \textbf{$\beta_{0y}$}& \textbf{$\beta_{1y}$}& \textbf{$\beta_{0z}$}& \textbf{$\beta_{1z}$}& \textbf{$\sigma^2$}\\
				\hline
				1 &Bias[\%] & 0.014 [2.8\%] & 0.012 [1.33\%] & -0.002 [-0.06\%] & 3.621 [-362.1\%] & -0.063 [-12.6\%] & 2.97 [297\%] & -0.001 [-1\%] & -0.003 [-0.3\%] \\  
				&SE& (0.109) & (0.038) & (0.959) & (0.666) & (0.133) & (0.7) & (0.005) & (0.054) \\   \hline
				2 &Bias[\%]& 0.056 [11.2\%] & -0.11 [-12.22\%] & 0.054 [1.54\%] & 3.755 [-375.5\%] & - & 4.343 [434.3\%] & - & 0.564 [56.4\%] \\
				& SE& (0.141) & (0.052) & (0.926) & (0.222) &  & (0.141) & & (0.08) \\
				\hline
				3 &Bias[\%]& 0.978 [195.6\%] & 0.04 [4.44\%] & 0.652 [18.63\%] & 3.505 [-350.5\%] & -0.163 [-32.6\%] & 3.006 [300.6\%] & 0.000 [0\%] & 0.018 [1.8\%] \\ 
				&SE& (0.466) & (0.037) & (0.919) & (0.202) & (0.117) & (0.544) & (0.005) & (0.054) \\ \hline
				4 &Bias[\%] & -& - & -& 3.279 [-327.9\%] & -0.25 [-50\%] & 2.949 [294.9\%] & 0.001 [1\%] & 0.7 [70\%] \\  
				&SE &  &  &  & (0.188) & (0.117) & (0.151) & (0.006) & (0.151) \\  \hline
				5 &Bias[\%] & 0.522 [104.4\%] & - & - & 3.456 [-345.6\%] & -0.035 [-7\%] & 2.959 [295.9\%] & 0.001 [1\%] & 0.608 [60.8\%] \\
				&SE & (0.199) &  & & (0.204) & (0.121) & (0.151) & (0.006) & (0.129) \\ 
				\hline
		\end{tabular}}\\
		\caption[Summary of MPLE estimates for simulated data]{Summary of parameter estimates for weak, moderate, and strong dependence regimes. Quantities in parentheses are the 5th and 95th percentiles}
		\label{EstResults}
	\end{table}
\end{sidewaystable}
\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{images/spatparests3.pdf}
\caption{Dependence Parameter Estimates for Simulated Data.}
\label{spatests}
\vspace{.5cm}
\centering
\includegraphics[scale=0.5]{images/meanparests4.pdf}
\caption{Regression Coefficient Estimates for Simulated Data.}
\label{meanests}
\end{figure}

\subsection{Confidence Interval Coverage}\label{CISIM}
The supplemental material in Caragea and Berg (2014) concluded that the confidence intervals from the parametric bootstrap procedure were slightly too narrow in the bivariate model, and similar results hold for the model considered in this work. For the bivariate mixed model, we investigated the confidence interval construction method for two sets of parameters in an intercept-only model. The parameters we used to simulate data are listed in the second column of Table \ref{CIcoverage}, with one weak dependence regime and one strong dependence regime. For each of the two parameter sets,  we simulated M=1,000 datasets and constructed a 95\% parametric bootstrap confidence interval for each. Due to the intensive computation required, we limited the bootstrap sample size to 500 for each interval, and kept every 20th estimate after a burn-in of 300 to ensure independence among samples.

Table \ref{CIcoverage} displays the means and standard errors of the 1,000 parameter estimates and the proportion of parametric bootstrap intervals that contained the true value used to simulate the data. For the weak regime, the Monte Carlo estimates are approximately unbiased, and the simulated data reflects the true value closely. Only $\eta_y$ had a notably large standard error, which aligns with the estimation study results from Section \ref{ParEstSim} and the simulation study of the bivariate auto-logistic model from Caragea and Berg (2014). All of the parameters had empirical coverage less than the 95\% nominal coverage, which agrees with the result from Caragea and Berg (2014) indicating that the bootstrap intervals are slightly too narrow. The largest under-coverage for the 6 estimates are $\rho$ and $\sigma^2$ at -2.1\%, which is still relatively close to the desired coverage.

For the strong dependence regime, the simulated data does not reflect the true marginal mean structure. Just as in Section \ref{ParEstSim}, $\delta$ and $\mu$ are not close to the true value used to generate the data due to strong local effects. However, the estimates for the dependence parameters and $\sigma^2$ are still approximately unbiased. The empirical 95\% interval coverage indicates that the intervals for $\rho$ and $\eta_y$ are slightly too wide, and the intervals for $\eta_z$ and $\sigma^2$ are too narrow. However, the average empirical coverage for the three dependence parameters is 93.8\%, which better aligns with the results for the weak regime.

We can see the breakdown in data generation in Figure \ref{conditionalCIcov}. The histogram of the 1,000 estimates of $\mu$ shows a clearly bimodal distribution. In the right panel, we observe a strong linear relationship between our estimates of $\delta$ and $\rho$ (R-squared in a simple linear regression was 0.9223), indicating an influence from the cross-dependence on data generation: the data reflect the conditional distributions rather than the marginal distributions. Additionally, we can see that the 95\% bootstrap confidence intervals that failed to contain the true parameter value ($\mu=1$) were clustered, while those that were successful in capturing the true value varied over the entire range of simulated data. This relationship is not observed in the simulated data under the weak dependence regime.

In general, the confidence intervals constructed via parametric bootstrap are too narrow, however not prohibitively so. All of the empirical coverages are within almost 2\% of the desired nominal rate when the model is not degenerate. If our interest is in both the covariate and dependence relationships, we have evidence that using the full bivariate spatial model provides reasonable estimates of uncertainty.
\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\includegraphics[width=\textwidth]{images/CIcovMuhist.pdf}%
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\includegraphics[width=\textwidth]{images/CImeanparcorr.pdf}%
	\end{subfigure}
	\caption[Mean parameter estimates under the strong dependence regime used for Monte Carlo study]{Estimated mean parameters for the 1,000 simulated datasets under the strong dependence regime.}
	\label{conditionalCIcov}
\end{figure}
\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		\multicolumn{5}{|c|}{\textbf{Weak Dependence}} \\ \hline
		\textbf{Parameter}& \textbf{True Value} & \textbf{MC Estimate} & \textbf{MC Std. Error} & \textbf{95\% CI Coverage} \\ \hline
		$\rho$ & 0.2& 0.202& 0.073 & 92.9\% \\ \hline
		$\eta_{z}$&0.5& 0.493& 0.083 & 93.2\% \\ \hline
		$\eta_{y}$ & 1& 0.959& 0.419 & 94.5\% \\ \hline
		$\delta$ & 0.5&0.508& 0.090 & 94.1\% \\ \hline
		$\mu$ & 1&1.001& 0.052 & 93.6\% \\ \hline
		$\sigma^2$ &1 & 0.996& 0.053 & 92.9\% \\ \hline
		\hline
		\multicolumn{5}{|c|}{\textbf{Strong Dependence}} \\ \hline
		\textbf{Parameter}& \textbf{True Value} & \textbf{MC Estimate} & \textbf{MC Std. Error} & \textbf{95\% CI Coverage} \\ 
		\hline
		$\rho$ & 5 & 5.024& 0.911&96.9\% \\ \hline
		$\eta_{z}$ & 0.9 & 0.901& 0.042 & 86.5\% \\ \hline
		$\eta_{y}$ & 3 &3.031& 0.710& 98.0\% \\ \hline
		$\delta$ & 0.5 &-1.683& 1.103& 49.4\% \\ \hline
		$\mu$ & 1 &-17.845& 10.419& 50.0\% \\ \hline
		$\sigma^2$ &100& 99.622 & 5.582& 92.6\% \\ \hline
	\end{tabular}
\caption[Bootstrap confidence interval coverage for simulated data]{Bootstrap confidence interval coverage for simulated data}
\label{CIcoverage}
\end{table}
\subsection{Marginal Behavior and Cross-Dependence}
Here we investigate some of the troubles with interpretation and breakdown due to the cross-dependence $\rho$ discussed in Section \ref{breakdown}. Because $\rho$ is a dependence parameter, its interpretation and governing behavior might be at least partially influenced by the Gaussian conditional variance $\sigma^2$. The goal is to find the relationship such that, for different values of $\sigma^2$, similar data can be generated by scaling $\rho$ appropriately.

Mean and dependence parameters were fixed at $\delta=0.5$, $\mu=1$, $\rho=1$, $\eta_z=0.5$, and $\eta_y=1.5$. For the fixed set of mean and dependence parameters, $\sigma^2$ was increased from 1 to 96 by 5 (20 values). For each value of $\sigma^2$, $\rho$ was multiplied by $\sqrt{\sigma^2}$ or kept as is. For each value of $\rho$ at each $\sigma^2$,  we simulated 50 datasets ($50\cdot20\cdot2=2000$ total datasets) on a 30 x 30 lattice. For each dataset, we calculated the marginal mean of the binary values and the observed S-value (a moment estimator of the univariate spatial dependence). For further details on the S-value, see Kaiser and Caragea (2009).

Figure \ref{sigmascales} displays the results of the simulations. In the left panel, it is clear that the marginal mean of $Y$ is not constant when $\rho$ is kept constant (solid line), and reverts to its marginal mean under independence of 0.6224 as $\sigma^2$ increases. When $\rho$ is scaled by multiplying by $\sqrt{\sigma^2}$ (dotted line), the observed mean of the data is relatively constant. In the right panel, the data simulated with $\rho\cdot\sqrt{\sigma^2}$ generates data with relatively constant spatial dependence. The data with $\rho$ held constant at 1 (solid line) is clearly not constant. This indicates that the cross-dependence $\rho$ scales at the same rate as $\sqrt{\sigma^2}$. As the conditional variance $\sigma^2$ increases with $\rho$ fixed, the cross-dependence goes to 0. The relationship does not appear quite perfect: the observed spatial dependence is not quite constant across values of $\sigma^2$ for cross-dependence scaled to $\rho*=\rho\cdot\sqrt{\sigma^2}$.
\begin{figure}[h]
	    \centering
	\begin{subfigure}{0.45\textwidth}
		\includegraphics[width=\textwidth]{images/scaletestYmean2.pdf}%
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\includegraphics[width=\textwidth]{images/scaletestSY3.pdf}%
	\end{subfigure}
	\caption[Mean and Spatial Dependence of binary data for increasing $\sigma^2$]{Observed simulated mean (left) and spatial dependence of the binary (right) nodes for increasing $\sigma^2$}.
	\label{sigmascales}
	\vspace{.8cm}
		\centering
	\begin{subfigure}{0.45\textwidth}
		\includegraphics[width=\textwidth]{images/transmissionZs3.pdf}%
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\includegraphics[width=\textwidth]{images/transmissionYs3.pdf}%
	\end{subfigure}
	\caption[Observed Spatial Dependence for Increasing Cross-Dependence]{Observed mean spatial dependence of simulated Gaussian (left) and binary (right) nodes for increasing $\rho$}
	\label{transmitS}
\end{figure}

Next, we investigate the idea of transmission of spatial dependence via $\rho$. The mean parameters are as before, except now $\sigma^2=1$ is fixed and we vary the cross-dependence parameter $\rho$. For two combinations of $\eta_z$ and $\eta_y$, (0.7, 0) and (0, 2.5), data were simulated across values of $\rho$ from 0 to 1.2. For each value of $\rho$, 50 datasets were simulated and the observed S-values were recorded for the Gaussian and binary nodes on the grid. Figure \ref{transmitS} displays the results from this simulation.

We expected that spatial dependence might be "transmitted" from the Gaussian to binary field and vice versa via the cross-dependence parameter $\rho$. In the right panel of Figure \ref{transmitS}, we observe that increasing the cross-dependence can increase the observed univariate spatial dependence for binary data, even if the true univariate dependence is 0 (solid line). The observed S-value for the binary nodes is 1.5 when $\rho=1.2$ and $\eta_z=0.7$. This means that the observed spatial dependence of $Y(s_i)$ is a moderate 1.5, even though the true value used to simulate the data is actually 0. A similar phenomenon  observed for the Gaussian variables in the dotted line in the left panel. Spatial dependence can be created by crossing the dependence structure from one variable type to the other, indicating that the dependence parameters might be at least partially confounded. While confounding would affect interpretation of the spatial structure, it should be noted from Section \ref{ParEstSim} that recovery of the true values is still possible in most cases and the model is still useful for inference.

\section{Application to Agricultural Field Trials} \label{AgTrials}
The continuous ranked probability score as outlined in Section \ref{ModCRPS} is illustrated on a small dataset repurposed from an agricultural field trial study. Lado, et al. (2013) provide data on the performance of 384 types of wheat under three different water regimes. While the original study concerned genomic selection of the wheat variations after spatial adjustment, for illustrative purposes this paper only concerns data from the yields. The data from the "Mild Water Stress" regime was used.

The wheat fields used were set on a regular lattice with 40 rows and 20 columns. Variables available were Treatment, Row, Column, Days to Head, Gross Yield, Thousand-Kernel Weight, and Number of Kernels per Spike. Gross Yield (in Thousands of Bushels) is used as the continuous Gaussian variable. We transformed Days To Head to a binary variable by setting the value to 1 if greater than 78 days (the wheat is slow to head) and 0 otherwise. The purpose of the analysis is to explain variation in Gross Yield and Days to Head using spatial and covariate information. After exploratory analysis, only Thousand-Kernel Weight appeared to be significantly related to either response variable after accounting for spatial effects. Thousand-Kernel Weight was used as a covariate on both sides of the model, and other variables were ignored. An image of the two response variables and the covariate is displayed in Figure \ref{wheatimage}. S-values give moment estimators of the spatial dependence as $S_z = 0.6345$ for the Gaussian data (Gross Yield) and $S_y = 1.1145$ for the binary data (Days to Head).
\begin{figure}[!t]
	\centering
	\begin{subfigure}{0.4\textwidth}
		\includegraphics[width=\textwidth]{images/wheatDayHead.pdf}%
	\end{subfigure}
	\begin{subfigure}{0.4\textwidth}
		\includegraphics[width=\textwidth]{images/wheatGrossYield.pdf}%
	\end{subfigure}
	\begin{subfigure}{0.4\textwidth}
		\includegraphics[width=\textwidth]{images/wheatTKW.pdf}%
	\end{subfigure}
	\caption{Response Variables and Covariate Used in Wheat Field Trial Study}
	\label{wheatimage}
\end{figure}
%\medskip

As in Section \ref{ParEstSim}, we estimated parameters for five different models and compared the full model to various reduced forms. In order to avoid possible edge effects, only interior nodes were used for estimation. For each model, we estimated parameters using the MPLE estimation procedure and constructed parametric bootstrap confidence intervals using a bootstrap sample size of 500. We computed the continuous-ranked probability score and corresponding skill separately for the Gross Yield and Days to Head for each model. Table \ref{wheatResults} summarizes the results from model estimation, providing the MPLE estimates and 95\% bootstrap confidence intervals for parameters in the top panel and CRPS/skill scores in the bottom. For each the two pairs of univariate models, we combine the results into a single line (rows 3 and 4).
%\medskip

 The 95\% bootstrap confidence interval for $\eta_{y}$ is quite wide and contains 0  in the full model, indicating an uncertain estimate of (possibly non-existent) spatial dependence among the Days to Head response variables on the lattice after accounting for covariates and cross-dependence. The spatial dependence estimates of 0.888 and 0.846 correspond to strong and weak/moderate spatial dependence in the Gaussian and binary variables, respectively. For an interior location, predicted Gross Yield is partially determined by taking $\frac{0.888}{4}=.222$ of the centered Gross Yield of each neighboring location. Estimation of cross-dependence $\rho$ varies widely across the considered models, and is insignificant for the intercept-only model with no covariates. For the full model, $\rho=0.299$ indicates a moderate cross-dependence between the response variables.

In the univariate spatial model, including Thousand-Kernel Weight as a covariate for Gross Yield indicates a relationship between the response variables that is larger than in the bivariate model, although the estimate is also more variable. For all models estimated, the covariate Thousand-Kernel Weight is a significant predictor for Days to Head (Y), and is only not significant for Gross Yield (Z) in the univariate spatial model. In the full model, a 1 gram increase in Thousand-Kernel Weight is associated with a 0.14 day decrease in number of days before heading and a .022 x 1000 = 22 bushel increase in Gross Yield, after accounting for other dependence. 
%\medskip

The estimated Gaussian conditional variance $\sigma^2$ is minimized for the full model, indicating that the full model with both spatial and covariate information accounts for the most variation in Gross Yield.  Using the continuous ranked probability score, the full model has the best in-sample performance among the five models. The non-spatial models perform significantly worse than the reduced spatial models for prediction of Gross Yield, but significantly better for the binary variable Days to Head. The full model is the only of the five options that exhibits non-negligible improvement over the constant mean model, thus we would select the full model using this criterion. The relative similarity between the full and univariate spatial models indicates that cross-dependence does not have a drastic effect on the model. While the full model is one of the best by the CRPS criterion, skill scores of 16.74 and 34.23 represent only modest improvements over the constant mean model.

\begin{table}[!h]
	\begin{tiny}
	\begin{tabular}{|l|c|c|c|c|c|c|c|c|}
		\hline
		\textbf{Model} & $\rho$ & $\eta_z$ & $\eta_y$ & Binary & 1000-Kernel Wt & Gaussian (Z)& 1000-Kernel Wt & $\sigma^2$ \\ 
		 &  &  &  & Intercept ($\beta_{0,y}$) & $\beta_{1,y}$ & Intercept ($\beta_{0,z}$) & ($\beta_{1,z}$) & \\
		\hline
	Full & 0.299 &0.888& 0.846& 6.591& -0.137& 6.842& 0.022& 1.387  \\ 
	& (0.127 , 0.474)& (0.795 , 1.008)& (0.000 , 1.947)& (5.109 , 7.794)& (-0.162, -0.106)&(5.915,  7.606)&(0.008 , 0.036)& \\\hline
	Intercept & 0.126 & 0.900 & 1.001& 0.336&-& 8.014&-&1.449 \\ 
	Only Spatial & (-0.026 , 0.264)& (0.809,  0.996)& (0.135 , 2.001)& (0.130 , 0.534)&  &(7.496 , 8.384)&& \\\hline
	Univariate &-& 0.618 & 1.232&  6.600&  -0.135&  7.065&  0.019& 1.448\\ 
	& & (0.634 , 0.921)& (0.622 , 2.710)& (4.319 , 7.104)&(-0.145 , -0.087)  &(6.969 , 8.370)&(-0.011 , 0.019)& \\\hline
	Univariate & - & - & - & 6.561& -0.134& 5.330&  0.057& 2.907  \\ 
	Non-Spatial&  &  &  & (5.177 , 7.818)&(-0.161 , -0.105)&(4.435 , 6.250)&(0.038 , 0.077)& \\\hline
	Bivariate & 0.233 & - & - & 6.873& -0.141& 5.442& 0.055& 2.822  \\ 
 	Non-Spatial	& (0.282 , 0.487)&  &  & (5.328 ,  8.266)&(-0.171 , -0.110)&(4.485 , 6.507)&(0.032 , 0.076)&\\
	\hline
	\end{tabular}
\end{tiny}

\vspace{.1cm}
\begin{tabular}{|l|l|l|l|l|}
	\hline
	 \textbf{Model} &$CRPS_y$ & $Skill_y$& $CRPS_z$ & $Skill_z$   \\
	 \hline
	 Full & 0.20 & 16.74 & 0.66 & 34.23\\
	 Intercept-Only Spatial & 0.24 & 1.62 & 0.66 & 33.46\\
	 Univariate & 0.21 & 14.82 & 0.70 & 29.57 \\
	 Univariate Non-Spatial& 0.22 & 8.11 & 0.97 & 2.59\\
	 Bivariate Non-Spatial & 0.22 & 10.44 & 0.96 & 3.37\\
	 \hline
\end{tabular}
\caption{Results of Model Estimation for Wheat Field Trial Data}
\label{wheatResults}
\end{table}

\section{Greater Prairie Chicken Presence and Vegetative Cover} \label{ChickenAnalysis}
The following implementation of the mixed bivariate MRF model illustrates some of the model's benefits in estimation of spatial dependence in the presence of strong dependence.
\subsection{Data Description}
The greater prairie chicken, \textit{Tympanuchus cupido}, is an endangered species of bird endemic to the tallgrass prairies of the central United States. Greater prairie chickens prefer to make nests in areas with large amounts of vegetative cover and do not migrate, thus we might be able to predict greater prairie chicken presence by measuring the condition of vegetation in the area. Moreover, presence of the greater prairie chicken might spark species conservation efforts or other causes that could encourage the preservation of the native tallgrass prairie ecosystems against the alternative of conversion to farmland or developments. Thus we hypothesize a positive relationship between vegetative cover and greater prairie chicken presence in an area.

We constructed a dataset to test this hypothesis by aggregating data from 3 online sources. Data on sightings of greater prairie chickens in North America were obtained from the Global Biodiversity Information Facility (GBIF) via the Cornell Lab of Ornithology's eBird database. Data on vegetation condition, specifically the Normalized Difference Vegetation Index (NDVI), is collected via satellite and are available from the USDA National Agricultural Statistics Service's VegScape explorer. This is a measure of the relative greenness of the biome, and is thus a good indicator of the amount of vegetation cover. In addition to these, we collected data on the soil conditions from the National Resource Conservation Service's Web Soil Survey database for use as possible covariates in the model.

In order to keep the illustration to a reasonable sample size, we focus on a portion of Lincoln County in western Nebraska. The satellite NDVI data are collected on a fine scale, so we aggregated the data onto a 31 x 31 grid and overlaid the soil data. The grid corresponds to areas of approximately 2 square miles for each point. The observations of the prairie chickens are limited to those since 1990 and the spring mating season months of March, April, and May, in which they are more active and more likely to be spotted. We used a snapshot of the NDVI from April 2018 as a representative example of the vegetation cover during this time of year. 
\begin{figure}[H] \label{ChickensNDVI}
	\begin{subfigure}{0.5\textwidth}
	\includegraphics[width=\textwidth]{images/NDVI2.pdf}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
	\includegraphics[width=\textwidth]{images/chickens2.pdf}
	\end{subfigure}
\caption[Raster images of NDVI and Greater Prairie Chicken observations]{NDVI (left) and Greater Prairie Chicken observations (right), after aggregation}
\end{figure}

\subsection{Data Analysis}
We modeled the relationship between NDVI (Gaussian response) and greater prairie chicken presence (binary response, with 1 indicating an observation at that location since 1990) as a bivariate spatial model. Exploratory analysis of the data indicates strong dependence for both variables, with S-values of $S_z = 0.994$ for the NDVI and $S_y = 3.308$ for the observed greater prairie chickens. The correlation between the response variables is 0.07, indicating a weak but possibly non-zero relationship between the response variables. Naive (non-spatial) linear regression with the covariates indicated significant linear relationships with several of the soil property covariates. We considered soil variables wind erodibility index, soil pH, percent sand composition, and water supply rating. All were significant in a multiple linear regression with NDVI as the response, however none were significant in a multiple logistic regression with prairie chicken presence as the response.

\begin{table}
	\centering
\begin{tabular}{|l|l|l|l|}
	\hline
	\textbf{Parameter} & Estimate & Std. Err. & 90\% Bootstrap C.I.\\
	\hline
	Y-Intercept($\beta_{0,y}$) & -0.417 & 1.962 &(-2.343 ,  4.183) \\
		\hline
	Wind Erodibility Index ($\beta_{1,y}$) & -0.005 & 0.006 & (-0.017  , 0.002)\\
		\hline
	\% Sand ($\beta_{2,y}$) &  0.024 &  0.018 & ( 0.003 ,  0.063)\\
		\hline
	Water Supply ($\beta_{3,y}$) &  0.019 & 0.045 & (-0.061 ,  0.083)\\
		\hline
	Z-Intercept($\beta_{0,z}$) &  204.543 & 15.970 & (-43.172 , 66.560)\\
		\hline
	$\sigma^2$&  16.765 & 0.949 & (15.246 , 18.245) \\
		\hline
	$\eta_y$ (Presence-Absence)& 3.613 & 0.697 & (2.356 ,  4.614) \\
		\hline
	$\eta_z$ (NDVI)& 0.991 & 0.017 & (0.955 ,  1.012) \\
		\hline
	$\rho$ (Cross-dependence) & 0.446 & .260 & (0.000 , 0.844)\\
	\hline
\end{tabular}
\caption[Model summary for greater prairie chicken / vegetation data]{Summary of model estimates for greater prairie chicken / vegetation data }
\label{chickenResults}
\end{table}

We estimated the model with several different combinations of the soil covariates, implementing the pseudo-likelihood estimation and parametric bootstrap (sample size M=500) for each. Results from model estimation and bootstrap inference for our selected final model are presented in Table \ref{chickenResults}. We found that after considering spatial dependence, the only significant relationships with the response variables were between percent sand and the presence of greater prairie chickens. This was contrary to our initial analysis of non-spatial multiple linear and logistic regressions, indicating that the presence of spatial dependence has a significant influence on the conclusions of the analysis. Given the results on simulated data in Section \ref{ParEstSim}, the strong dependence in this data should make us hesitant to draw too many conclusions about the covariate relationships. Moreover, even the statistically significant covariate relationship does not appear to be practically significant.

The estimate of binary spatial dependence was $\eta_y = 3.613$, indicating strong dependence in the binary field but well below the upper bound as outlined in Section \ref{breakdown}. The estimate of spatial dependence in the continuous variable is $\eta_z = 0.991$, which is very near the boundary of the parameter space. This indicates very strong dependence among the NDVI values, which we might expect given the aggregation of the original fine-scale measurements in the data. The cross-dependence among the response variables is estimated to be $\rho = 0.446$, which is quite strong when we consider the presence of the other strong spatial dependence parameters. Here we note that the estimates of dependence are close to the strong parameter set used to study estimation and confidence interval procedures in Section \ref{SimStudy}.

The estimate of $\rho$ suggests a significant cross-dependence, thus we conclude that there is a benefit to using a bivariate spatial model in this analysis. Just as in the initial exploratory analysis, there is a positive correlation between our two response variables: it is more likely that we observe greater prairie chickens in areas with heavier vegetation cover. This (mildly) supports the hypothesis that greater prairie chickens prefer heavier vegetative cover to make their nests.

%The fitted model leads to a $CRPS_y$ of 0.1254 and a corresponding skill score of -21.81 for the binary data, indicating overfitting. For the NDVI data, we have $CRPS_z$ of 2.25 with corresponding skill score of 55.76 for the Gaussian data. This is a very notable improvement over a constant mean model.

\section{Conclusion} \label{Conclusion}
This work proposes a Markov random field model with bivariate response variables that belong to different distributions within the exponential family. The model follows from previous work in univariate Markov random field models and network models, with a constructed joint density function that follows the familiar form of one-parameter exponential families often used in generalized linear models. This joint density builds from conditionally-specified distributions on the nodes of the graph. Estimation and inference relies on maximum pseudo-likelihood and parametric bootstrap, following the node-conditional specification. The MPLE estimation and parametric bootstrap are relatively simple to implement, but can be computationally demanding and may not be reliable when the spatial dependence is very strong.

There are many readily apparent extensions of the rather simple model described throughout this work. Additional dependence structures, such as extended neighborhoods or temporal dependence beyond that described in Section \ref{framework}, can be modeled by adding additional terms to the node-conditional distributions as in (\ref{condY}) and (\ref{condZ}) or generalizing the indices of the dependence parameters. The work in mixed graphical structures discussed in Section \ref{MixedMRF} could also allow the extension of the bivariate model to higher-dimensional responses with perhaps more than 2 different distribution types, such as nodes with Poisson or even Gamma-family distributions. While the initial stage of specifying node-conditional distributions is relatively straightforward, caution must be taken to ensure that the conditional distributions can then form a valid joint distribution.
%\medskip

Even if an extended model satisfies the conditions for a valid corresponding joint distribution, model degeneracy poses a larger obstacle to the proposed possible extensions. With each additional spatial or temporal neighbor added to the model, the conditional structure has another constraint that must be satisfied in order to ensure observed marginal behavior matches expected marginal behavior. As discussed in Section \ref{breakdown}, determining parameter spaces for the spatial dependence structure that ensures reliable estimation and interpretation is an open question. Moreover, different structures require different centering schemes to allow for interpretable model parameters. Adding different distribution types to the model requires significant analytical work that is not considered here.  We encountered difficulties with the four-nearest neighbor with one cross-dependent neighbor structure here, which is perhaps the simplest case of this type. More complex models certainly require even more caution, despite our flexible method for specifying valid distributions.
%\medskip

Although we have some open issues with model behavior, the multivariate Markov random field model still has many favorable properties. The flexible conditionally-specified model structure, which reduces to node-wise regression models, allows easy modeling of any one-parameter exponential family distribution with separated structures for covariates and dependence parameters. The computation required for estimation and inference is relatively simple when compared to alternatives, while still allowing for easy-to-interpret model parameters. When the purpose of an analysis is prediction at unobserved locations, other models may more adequately capture variation due to spatial dependence. The bivariate mixed Markov random field model is most appropriate when quantifying and interpreting the spatial dependence structure is integral to understanding the scientific question of interest.
%\medskip

%\newpage
\begin{thebibliography}{9}\setstretch{1}
	\bibitem  {Besag} Besag, J. (1974). Spatial Interaction and the Statistical Analysis of Lattice Systems. Journal of the Royal Statistical Society. Series B (Methodological), 36(2), 192-236. 
	
	\bibitem  {Besag2} Besag, J. (1975). Statistical Analysis of Non-Lattice Data. Journal of the Royal Statistical Society. Series D (The Statistician), 24(3), 179-195.
	
	\bibitem {BesagYorkMollie} Besag, J., York, J. and Mollie, A. (1991). Bayesian image restoration, with two applications in spatial statistics. Ann Inst Stat Math 43: 1.
	
	\bibitem  {CarageaBerg} Caragea, P.C. and Berg, E. (2014). A centered bivariate spatial regression model for binary data with an application to presettlement vegetation data in the Midwestern United States. J. Agric. Biol. Environ. Stat. 19, 453–471.
	
	\bibitem  {Chen} Chen, S., Witten, D. M., and Shojaie, A. (2014). Selection and estimation for mixed graphical models. Biometrika, 102(1), 47-64. 
	
	\bibitem {deLeon} de Leon, A. R. and Wu, B. (2011), Copula-based regression models for a bivariate mixed discrete and continuous outcome. Statist. Med., 30: 175-185.
	
	%\bibitem {DuttaMondal} Dutta, S. and Mondal, D. (2015), An h-likelihood method for spatial mixed linear models based on intrinsic auto‐regressions. J. R. Stat. Soc. B, 77: 699-726.
	%\bibitem{ebird} eBird (2017). eBird: An online database of bird distribution and abundance [web application]. eBird, Cornell Lab of Ornithology, Ithaca, New York. Available: http://www.ebird.org. (Accessed: 31 October 2018).
	
	\bibitem {Gelfand} Gelfand, A., and Vounatsou, P. (2003). Proper multivariate conditional autoregressive models for spatial data analysis. Biostatistics, 4(1), 11-15.
	
	\bibitem{GBIF} GBIF.org 	($31$st October $2018$). GBIF Occurrence Download. https://doi.org/10.15468/dl.powetx
	
	\bibitem {GenestNeslehova} Genest, C. and Neslehova, J. (2007). A Primer on Copulas for Count Data. ASTIN Bulletin, 37(2), 475-515.
	
	\bibitem {GneitingCRPS}  Gneiting, T. and Raftery, A. (2007). Strictly Proper Scoring Rules, Prediction, and Estimation. Journal of the American Statistical Association, 102:477, 359-378.
	
	\bibitem {Griffith} Griffith, Daniel. (2002). A Spatial Filtering Specification for the Auto-Poisson Model. Statistics \& Probability Letters. 58. 245-251. 10.1016/S0167-7152(02)00099-8.
	
	\bibitem {GuanHaran}  Guan, Y. and Haran, M. (2018). A Computationally Efficient Projection-Based Approach for Spatial Generalized Linear Mixed Models, Journal of Computational and Graphical Statistics.
	
	\bibitem {HardouinCressie} Hardouin, C. and Cressie, N. (2018). Two-scale Spatial Models for Binary Data. N. Stat Methods Appl (2018) 27: 1. 
	
	\bibitem  {Haslbeck} Haslbeck, J.M.B, and Waldorp, L.J. (2015). Structure estimation for mixed graphical models in high dimensional data. arXiv:1510.05677.
	
	\bibitem {HodgesReich} Hodges, J. and Reich, B. (2010). Adding Spatially-Correlated Errors Can Mess Up the Fixed Effect You Love. The American Statistician, 64:4, 325-334.
	
	\bibitem {HughescopCAR} Hughes, J. (2015) copCAR: A Flexible Regression Model for Areal Data. Journal of Computational and Graphical Statistics, 24:3, 733-755.
	
	\bibitem {HughesHaran} Hughes, J., and Haran, M. (2013). Dimension reduction and alleviation of confounding for spatial generalized linear mixed models. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 75, 139–159. 
	
	\bibitem{HughesHaranCaragea} Hughes, J. , Haran, M. and Caragea, P. C. (2011), Autologistic models for binary data on a lattice. Environmetrics, 22: 857-871.
	
	\bibitem{JordanScoringRules} Jordan, A., Kruger, F., and Lerch, S. (2016). scoringRules: Scoring Rules for Parametric and Simulated Distribution Forecasts. Available at\\ https://cran.r-project.org/web/packages/scoringRules 
	
	\bibitem  {Kaiser1} Kaiser, M.S. (2007). Statistical Dependence in Markov Random Field Models. Statistics Preprints, 57. https://lib.dr.iastate.edu/stat\_las\_preprints/57 .
	
	\bibitem  {KaiserCaragea} Kaiser, M. S. and Caragea, P. C. (2009). Exploring Dependence with Data on Spatial Lattices. Biometrics, 65: 857-865. 
	
	\bibitem  {Kaiser2} Kaiser, M., Caragea, P., and Furakawa, K. (2012). Centered Parameterizations and Dependence Limitations in Markov Random Field Models. Journal of Statistical Planning and Inference, Volume 142, Issue 7, 2012, 1855-1863, ISSN 0378-3758.
	
	\bibitem  {KaiserCressie} Kaiser, M., and Cressie N. (2000). The Construction of Multivariate Distributions from Markov Random Fields.  Journal of Multivariate Analysis. 73. 199-220. 10.1006/jmva.1999.1878.
	
	\bibitem{LadoEtAl} Lado, B., Matus, I., Rodríguez, A., Inostroza, L., Poland, J., Belzile, F., del Pozo, A., Quincke, M., Castro, M., von Zitzewitz, J. (2013). Increased genomic prediction accuracy in wheat breeding through spatial adjustment of field trial data. G3 (Bethesda, Md.), 3(12), 2105-14. doi:10.1534/g3.113.007807
	
	\bibitem  {LeeHastie} Lee, J. and Hastie, T.J. (2015). Learning the Structure of Mixed Graphical Models. Journal of Computational and Graphical Statistics, 24:1, 230-253.
	
	\bibitem {Liang}  Liang, F. (2010). A double Metropolis$-$Hastings sampler for spatial models with intractable normalizing constants. Journal of Statistical Computation and Simulation, 80:9, 1007-1022.
	
	\bibitem{Mardia} Mardia, K. (1988). Multi-dimensional multivariate Gaussian Markov random fields with application to image processing. Journal of Multivariate Analysis, 24(2), 265-284.
	
	\bibitem {Musgrove} Musgrove, D. R., Hughes, J., and Eberly, L. E. (2016). Hierarchical copula regression models for areal data. Spatial Statistics, 17, 38-49.
	
	\bibitem {ReichHodges} Brian J. Reich, Hodges, J., \& Vesna Zadnik. (2006). Effects of Residual Smoothing on the Posterior of the Fixed Effects in Disease-Mapping Models. Biometrics, 62(4), 1197-1206.
	
	\bibitem {RueHeld} Rue, H., Held, L., Reid, N., Keiding, N., Tibshirani, R., Louis, T., Tong, H., Isham, V. (2005). Gaussian Markov Random Fields. New York: Chapman and Hall/CRC.
	
	\bibitem {SainCressie} Sain, S., Furrer, R., and Cressie, N. (2011). A spatial analysis of multivariate output from regional climate models. The Annals of Applied Statistics, 5(1), 150-175.
	
	\bibitem {soilsurvey} Soil Survey Staff, Natural Resources Conservation Service, United States Department of Agriculture. Web Soil Survey. Available online at the following link: https://websoilsurvey.sc.egov.usda.gov/. (Accessed: 31 October 2018).
	
	\bibitem {SunClayton} Sun, L., and Clayton, M. (2008). Bayesian Analysis of Crossclassified Spatial Data with Autocorrelation. Biometrics, 64(1), 74-84. 
	
	\bibitem {vegscape} Yang, Z., Yu, G., Di, L., Zhang, B., Han, W., and Mueller, R. (2013). Web service-based vegetation condition monitoring system - VegScape, Geoscience and Remote Sensing Symposium (IGARSS) 2013 IEEE International, 3638-3641.
	
	%\bibitem  {Wakefield} Wakefield, K. (2017). ''Exploring Dependence in Binary Markov Random Fields''
	\bibitem{Wall} Wall, Melanie. (2004). A close look at the spatial structure implied by the CAR and SAR models. Journal of Statistical Planning and Inference. 121. 311-324. 10.1016/S0378-3758(03)00111-3.
	
	\bibitem{Yang} 	Yang, E., Baker, Y., Ravikumar, P., Allen, G. and Liu, Z.. (2014). Mixed Graphical Models via Exponential Families. Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics, in PMLR 33:1042-1050.
	
	
\end{thebibliography}
\newpage
\appendix
\section{Supplemental Model Development Discussion}
\subsection{Proof for a Valid Joint Distribution} \label{JointProof}
\begin{proof}
	The joint distribution $p(\boldsymbol{\utilde{y}},\boldsymbol{\utilde{z}})$ is valid if it is integrable, i.e, that the denominator in (\ref{jointNeg}) is finite over the paramter space.
	
	Because any binary variable has only 2 outcomes, for a lattice with $n$ locations we have $2^n$ possible outcomes for $n$ binary variables, thus the sum over the binary nodes is finite. We then condition on the binary nodes and show that this joint conditional distribution is integrable is finite.
	
	Conditioning on the binary nodes, the resulting conditional expectation for the remaining Gaussian nodes as in (\ref{condZ}) conditional upon all other locations can then be written as $E\lbrack z(s_i) | \boldsymbol{z}(\bar{s}_i) \rbrack = \mu_i^* + \frac{\eta_{z}}{M_i}\sum_{j\in N_i} (z(s_j)-\mu_j*)$, where $\mu_i^* = \mu_i + \rho(y(s_i)-\frac{\exp(\delta_i)}{1+\exp(\delta_i)})$ and the full joint distribution for the Gaussian nodes conditioned on the binary values, with common variance $\sigma^2$, is multivariate Gaussian as in equation (4.10) of Besag (1974):
	\begin{equation} \label{multNorm}
	p(\boldsymbol{\utilde{z}}|\boldsymbol{\utilde{y}}) \propto (2\pi\sigma^2)^{-n/2}|\boldsymbol{H}|\exp\lbrace\frac{-1}{2\sigma^2}(\boldsymbol{\utilde{z}} - \boldsymbol{\utilde{\mu^*}})^T\boldsymbol{H}(\boldsymbol{\utilde{z}} - \boldsymbol{\utilde{\mu^*}})\rbrace
	\end{equation}
	where $\boldsymbol{\utilde{z}} = (z(s_1),...,z(s_n))^T$, $\boldsymbol{\utilde{\mu^*}} = (\mu_1*,...,\mu_n*)$, and $\boldsymbol{H}$ is an $n$ x $n$ matrix with 1 on the diagonals and $\boldsymbol{H}_{ij} = \frac{-\eta_z}{M_i}$ for $j \in N_i$, $j\neq i$, all other entries being 0. 
	
	If $\sum_{i=1}^{M_i}\frac{\eta_z}{M_i} = \eta_z < 1$, then $\boldsymbol{H}$ is strictly diagonally dominant, and thus $\boldsymbol{H}$ is non-singular. %We could also multiply the common variance $\sigma^2$ through to $\boldsymbol{H}$, such that the diagonal entries are $1/\sigma^2$, which then requires the constraint $\eta_z < 1/\sigma^2$ for positive definiteness. 
	By properties of multivariate Gaussian distributions, non-singular $\boldsymbol{H}$ implies that (\ref{multNorm}) is a valid joint probability density and is integrable. Because the binary values are defined only on $2^n$ outcomes, if %$\eta_z < 1/\sigma^2$ or
	$\eta_z<1$ then we have
	\begin{math}
	\int_{\Omega_{Y,Z}}p(\boldsymbol{\utilde{y}},\boldsymbol{\utilde{z}})d\boldsymbol{\utilde{y}}d\boldsymbol{\utilde{z}} = \sum_{\Omega_Y}\int_{\Re}p(\boldsymbol{\utilde{z}}|\boldsymbol{\utilde{y}})d\boldsymbol{\utilde{y}}d\boldsymbol{\utilde{z}}<\infty
	\end{math}
	and thus the full joint distribution is valid. 
\end{proof}

\subsection{A Relationship Between Cross-dependence and Spatial Effects on Marginal Behavior} \label{specUB}
In what follows, we provide some speculative preliminary investigation between the various dependence parameters in the bivariate mixed MRF model. We borrow from the ideas of Kaiser (2007) and the interpret $\rho$ as a covariance parameter between $Y$ and $Z$ to find a standard bound for the cross-dependence parameter. Since we have centered the data, $\rho$ is then a reflection of a relationship between spatial parameters. For a fixed spatial dependence, we wish to find a function of $\eta_y$ and $\eta_z$ (i.e., find values of $\rho$ such that the data generated look similar for varying $\eta_y$ and $\eta_z$). We can use the definition of correlation, and fix the value of the correlation and solve for covariance:\\
\begin{math}
Corr\left[z(s_i)-\mu, y(s_i)-logit^{-1}(\delta)\right] = \frac{Cov\left[z(s_i)-\mu ,  y(s_i)-logit^{-1}(\delta)\right]}{\sqrt{Var(z(s_i)-\mu)}\sqrt{Var(y(s_i)-logit^{-1}(\delta))}}\\
\approx \frac{\rho}{\sqrt{Var(z(s_i)-\mu)}\sqrt{Var(y(s_i)-logit^{-1}(\delta))}}\\
\approx \frac{\rho}{\sqrt{\eta_z}\sqrt{\eta_y}}
\end{math}\\
We can then hold the left side constant (at 1, for example), and then solve for $\rho$ to get $\rho = \sqrt{\eta_z}\sqrt{\eta_y}$.

We now wish to find an "upper bound" for $\rho$, denoted here as $\ddot{\rho}$, such that $\lvert\rho\rvert < \ddot{\rho}$ ensures non-degenerate model behavior. We start at the bounds for our univariate spatial parameters and work backwards, so that under independence  ($\eta_z = \eta_y = 0$) the marginal expectations of the model approximately match the conditional expectations. For univariate models, recall from Section \ref{breakdown} that the upper bound for $\eta_z$ is $\ddot{\eta_z}=1$ and the upper bound for $\eta_y$ depends on $\delta$ with $\ddot{\eta_y}\geq4$ (Figure \ref{etaUB}). With these two values, we propose an upper bound for $\ddot{\rho}$:
\begin{equation*}
\ddot{\rho}/\sqrt{\sigma^2} = \sqrt{(\ddot{\eta_z})(\ddot{\eta_y})}
\end{equation*}
\begin{equation} \label{rhoubeq}
\implies \ddot{\rho} = \sqrt{(\sigma^2\ddot{\eta_y})}
\end{equation}
Under constant variance (say, $\sigma^2=1$), (\ref{rhoubeq}) becomes $\ddot{\rho}=\sqrt{\ddot{\eta_z}\ddot{\eta_y}} = \sqrt{\ddot{\eta_y}}$.

The standard bound given by (\ref{rhoubeq}) is a bound for $\rho$ when the $\eta_z=\eta_y=0$ (i.e., a non-spatial model), such that the model degenerates as $\rho$ approaches or passes $\ddot{\rho}$. For the more useful case in which the spatial dependence parameters are non-zero, we can work backward from (\ref{rhoubeq}) to find a function for the upper bound for $\rho$. With $\ddot{\eta_z}$ and $\ddot{\eta_y}$ as defined previously, we simply take the upper bounds and subtract the actual parameter values to get our function:
\begin{equation}
\label{rhoubuns}
\rho\left(\eta_z,\eta_2\right) =\sqrt{\sigma^2}\sqrt{(1-\eta_z)(\ddot{\eta_y}-\eta_y)} 
\end{equation}
which for $\sigma^2=1$ simplifies to
\begin{equation}
\label{rhoubscale}
\rho\left(\eta_z,\eta_y\right) =\sqrt{(1-\eta_z)(\ddot{\eta_y}-\eta_y)} 
\end{equation}
With (\ref{rhoubuns}) and (\ref{rhoubscale}) we now have a useful result which allows us to quantify the dependence across our two variables of interest in the context of the independent spatial dependence parameters. For varying levels of $\eta_z$ and $\eta_y$, our model will degenerate as the realized $\rho$ approaches $\rho(\eta_z, \eta_y)$. Additionally, the proposed function in (\ref{rhoubuns}) also implies that we can generate similar realizations of bivariate spatial data for different values of $\eta_z$ and $\eta_y$ by adjusting $\rho$. We could generate data such that the $y(s_i)$ values behave as if strongly dependent (i.e., $\eta_y>3.5$) even with a true value of $\eta_y = 0.1$ by varying our $\rho$ and $\eta_z$ accordingly through (\ref{rhoubscale}).

Because the smallest upper bound for $\eta_y$ is $\ddot{\eta_y}=4$, we speculate an uniform upper bound for $\rho$ as a function of the other dependence parameters as $\ddot{\rho} =\sqrt{\sigma^2}\sqrt{(1-\sigma^2\eta_z)(4-\eta_y)}$, or scaled/reparameterized as $\ddot{\rho} =\sqrt{(1-\eta_z)(4-\eta_y)}$. This bound works reasonably well when dependence is weak to moderate, in that we can simulate data that looks approximately the same for varying values of $\eta_y$ and $\eta_z$ by adjusting $\rho$ such that the the equality above holds. This relationship breaks down for larger values of $\eta_y$ and $\eta_z$, but appears a more reasonable upper bound for $\rho$ than the conservative suggestion in Section \ref{breakdown}. The above derivation is only an outline and is not rigorous, but seems to be plausible.

We provide some illustrations of the relationship among dependence parameters here, by assessing the marginal (observed) behavior of simulated data for varying levels of the dependence parameters. The simulation study process was as follows:
\begin{enumerate}
	\item Fixed parameters $\eta_y = 1$, $\sigma^2=10000$, $\mu=1$, and $\delta=0.5$
	\item Calculate a "baseline" relationship by plugging $\rho=100$ and $\eta_z = 0$ to (\ref{rhoubuns}), to get $\rho_b=1.749871$.
	\item For each $\eta_{z*} \in \lbrace 0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8 \rbrace$:
	\begin{itemize}
		\item Generate 20 datasets for two different values of the cross-dependence parameter: $\rho_1 = 100$ and $\rho_2 = 100\cdot\frac{\rho_*}{\rho_b}$, where $\rho_*$ is the value from plugging the respective $\eta_{z*}$ value into (\ref{rhoubuns}).
		\item Calculate average observed sample means and S-values (observed spatial dependence).
	\end{itemize}
\end{enumerate} 
If our relationship in (\ref{rhoubscale}) is reasonable, we would expect that the observed data approximately reflects the expected marginal behavior under independence. Figure \ref{testzsbound} displays results from the simulations. We can see that, as we increase $\eta_z$, keeping $\rho_1$ constant causes the observed marginal mean and observed spatial dependence (solid lines) of the binary data to drift away from the expected mean under independence. The data generated using the transformed $\rho_2$ (dashed lines) produces approximately constant mean and spatial dependence across $\eta_z$ values, indicating that for constant $\sigma^2$, we can generate data that looks the same for different combinations of spatial dependence parameters! We only need to adjust using (\ref{rhoubuns}).

We then performed the same procedure for varying levels of $\eta_{y}$. Here, we fixed $\eta_z=0.5$ and used the sequence of $\eta_{y*} \in \lbrace 0, 0.2, 0.4,\dots,3.8,4\rbrace$, with the other parameters as before. Again, we generated 20 datasets for $\rho_1=100$ and $\rho_2=100\cdot\frac{\rho_*}{\rho_b} $, where $\rho_*$ values are determined by inputting each $\eta_{y*}$ into (\ref{rhoubuns}). The results, displayed in Figures \ref{testysboundy} and \ref{testysboundz}, were similar: the data generated using constant $\rho_1$ (solid lines) drifted away from expected marginal behavior. By transforming to $\rho_2$ (dashed lines), we were able to generate data that was approximately constant across all values of $\eta_y*$.

\begin{figure}[H]
	\centering
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\textwidth]{images/transformEZymean2.pdf}%
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\textwidth]{images/transformEZyspat2.pdf}%
	\end{subfigure}
	\caption[Binary mean and spatial dependence for increasing $\eta_z$]{Observed simulated mean (left) and spatial dependence (right) of the binary nodes for increasing $\eta_z$, for two choices of $\rho$}
	\label{testzsbound}
	%\vspace{.8cm}
\end{figure}
\begin{figure}[H]
	\centering
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\textwidth]{images/transformEYymean.pdf}%
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\textwidth]{images/transformEYyspat.pdf}%
	\end{subfigure}
	\caption[Binary mean and spatial dependence for increasing $\eta_y$]{Observed simulated mean (left) and spatial dependence (right) of the binary nodes for increasing $\eta_y$, for two choices of $\rho$}
	\label{testysboundy}
\end{figure}
	\begin{figure}[H]
	\centering
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\textwidth]{images/transformEYzmean.pdf}%
	\end{subfigure}
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\textwidth]{images/transformEYzspat.pdf}%
	\end{subfigure}
	\caption[Gaussian mean and spatial dependence for increasing $\eta_y$]{Observed simulated mean (left) and spatial dependence (right) of the Gaussian  nodes for increasing $\eta_z$, for two choices of $\rho$}
	\label{testysboundz}
\end{figure}

Unfortunately, we also see in the plots that the relationship is not perfectly linear, only approximate. Moreover, this relationship tends to break down when $\eta_y$ or $\eta_z$ are near their univariate bounds, as the within-type spatial dependence overwhelms the cross-dependence effects. Despite this and the rather non-rigorous derivation, it appears there is a reasonable approximation for the relationship.

\subsection{Alternative Models for Lattice Data}
Many alternatives to the auto-models  have been considered for lattice data, the two most prominent being the spatial generalized linear mixed model and copula models. In the spatial generalized linear mixed model (SGLMM) as in Besag, York, and Mollie (1991), variability due to spatial dependence is modeled as spatial random effects $\boldsymbol{\psi} = \lbrace \psi_1,...\psi_n\rbrace$. Typically, these random effects are assumed to come from a zero-mean Gaussian random field as in Rue and Held (2005) and connected via an adjacency $\textbf{A}$ or spatial weights matrix $\textbf{W}$  that defines the graph structure. The distribution of the response variables conditional on these spatial random effects and possible fixed covariate effects is then modeled as an suitable distribution in the typical procedure of a generalized linear mixed model. This model can then be extended to a multivariate model as in Gelfand and Vounatsou (2003) with a Gaussian MRF of random effects. The specification of the SGLMM's covariance matrix $\boldsymbol{\Sigma}$ via design of $\textbf{A}$ or $\textbf{W}$ provides flexibility and leads to improved prediction capability over auto-models, but at a cost.
%\medskip

Estimation of the random effects $\boldsymbol{\psi}$ is computationally burdensome for large lattices due to the required repeated inversion of $\boldsymbol{\Sigma}$ or the (typically sparse) precision matrix $\textbf{Q}$ in maximum likelihood estimation Hughes and Haran (2013). (Guan and Haran (2018)) or filtering via the addition of synthetic covariates based on spatial eigenvectors (Griffith (2002)). The dimension reduction methods for SGLMMs also partially alleviate the more troublesome property of confounding (Hughes and Haran (2013)), which inhibits the recovery of regression parameters (Hodges and Reich (2010)). In addition to this confounding, the modeling of spatial dependence via random effects can lead to counter-intuitive interpretations of spatial correlation (Wall (2004)).  
%\medskip

Spatial dependence can also be incorporated into regression models via copulas. One method is the copCAR (Hughes (2015)), in which the CAR precision matrix $\textbf{Q}$ (as in the SGLMM)  or other desirable covariance structure (Musgrove, Hughes, and Eberly (2016)) is modeled as the Gaussian copula and then linked from the copula to a \textit{marginal} distribution for the responses via the probability integral transform. The copula model is flexible in that it allows for positive spatial dependence for any type of response distribution. It is also a marginal regression model, in that regression coefficients have interpretations in terms of the marginal distribution of the response instead of conditional distributions (as in auto-models and SGLMMs). Another convenient property of copula-based models, as in de Leon and Wu (2011), is the extension to the multivariate mixed response distributions considered in this work. One could conceivably use copulas to model a wide range of dependence and response structures without requiring the unique analytical work to justify each model (as in Section \ref{BivMMRF} here).
%\medskip

The class of auto-models considered in Sections \ref{prelims} and \ref{BivMMRF} have many preferable properties despite the favorable characteristics of the models considered above. In (\ref{condY}) and (\ref{condZ}), the spatial dependence parameters $\eta_{y}$, $\eta_{z}$, and $\rho$ are modeled directly in the scale of the response distributions, rather than through the specification of the latent Gaussian random fields above. Genest and Neslehova (2007) point out that for discrete marginal distributions (e.g. binary), the joint distribution is only defined on the support for the marginals and thus interpretation of dependence parameters is subject to extreme caution. Because we have directly specified via conditional distributions in (\ref{condY})-(\ref{condZ}), we avoid the interpretability/identifiability  issues of copula models. Even if dependence is now defined in terms of conditional instead of marginal means, spatial dependence in automodels has an intuitive interpretation in terms of neighboring values rather than the somewhat nebulous random effects of SGLMMs and copula models. Moreover, the regression coefficients (global structure) are not confounded with the dependence parameters (local structure) in the centered model, such that the regression coefficients $\boldsymbol{\beta}$ have convenient interpretations in terms of marginal means (like copula models) rather than the conditional means as in SGLMMs (Caragea and Berg (2014)).
\section{Supplementary Figures for Prairie Chicken Dataset} \label{ChickenData}
\begin{figure}[H]
	\centering
		\includegraphics[scale=0.9]{images/ndvi4172018.png}
	\caption[Satellite image of Lincoln County, NE]{Satellite image of Lincoln County, Nebraska, downloaded from USDA's VegScape application. Area between the lines was used in the analysis}
\end{figure}
		\vspace{.5cm}
\begin{figure}[H] \label{NDVIhist}
	\centering
	\includegraphics[scale=0.35]{images/NDVIhist2.pdf}
	\caption{Histogram of NDVI values used in analysis}
\end{figure}
\begin{figure}[ht]
\centering
\begin{subfigure}{0.3\textwidth}
		\includegraphics[width=\textwidth]{images/werghist.pdf}
\end{subfigure}
\begin{subfigure}{0.3\textwidth}
	\includegraphics[width=\textwidth]{images/sandhist.pdf}
\end{subfigure}
\begin{subfigure}{0.3\textwidth}
	\includegraphics[width=\textwidth]{images/watersupplyhist.pdf}
\end{subfigure}
\\
\begin{subfigure}{0.33\textwidth}
	\includegraphics[width=\textwidth]{images/werg.pdf}
\end{subfigure}
\begin{subfigure}{0.3\textwidth}
	\includegraphics[width=\textwidth]{images/pctsand.pdf}
\end{subfigure}
\begin{subfigure}{0.3\textwidth}
	\includegraphics[width=\textwidth]{images/watersupply.pdf}
\end{subfigure}
	\caption{Histograms and raster images of covariates used in analysis}
\end{figure}

\end{document}